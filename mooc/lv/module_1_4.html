<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>4.nodarbība: Interneta un sociālo mediju loma informācijas traucējumu radīšanā</title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="This course is designed to help individuals to become smart consumers of news and informed participants in civic life." name="description"/>
<meta content="ESSENTIAL Project Turkish Team" name="author"/>
<!-- Le styles -->
<link href="../css/bootstrap.css" rel="stylesheet"/>
<link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/black-tie/jquery-ui.css" rel="stylesheet"/>
<link href="../css/jquery.tocify.css" rel="stylesheet"/>
<link href="../css/prettify.css" rel="stylesheet" type="text/css">
<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<!-- Le fav icon -->
<link href="../assets/ico/favicon.ico" rel="shortcut icon"/>
<style>
    body {
      padding-top: 20px;
    }
    p {
      font-size: 16px;
    }
    .headerDoc {
      color: #005580;
    }

@media (max-width: 767px) {
    #toc {
        position: relative;
        width: 100%;
        margin: 0px 0px 20px 0px;
    }
}
    </style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VFJPMP12NF"></script>
<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
 		gtag('js', new Date());

 		gtag('config', 'G-VFJPMP12NF');
	</script>
</link></head>
<body>
<div class="container-fluid">
<div class="row-fluid">
<div class="span3">
<div id="toc">
<center>
<br/>
<code class="trainee">Trainees Edition</code>
<code class="trainer">Trainers Edition</code>
<code class="select"><a href="?userType=trainee">Trainees Edition</a></code>
<code class="select"><a href="?userType=trainer">Trainers Edition</a></code>
<a href="#top"><img src="../img/index/essential_logo.jpg" width="75%"/></a>
<p><a class="btn btn-secondary btn-small" href="index.html">MOOC HOME</a></p>
</center>
</div><!--/.well -->
</div><!--/span-->
<div class="span9">
<div class="hero-unit">
<h1 id="4-nodarbiba-interneta-un-socialo-mediju-loma-informacijas-traucejumu-radisana"><strong>4.nodarbība: Interneta un sociālo mediju loma informācijas traucējumu radīšanā</strong></h1>
</div>
<h2 id="nodarbibas-apraksts"><strong>Nodarbības apraksts</strong></h2>
<p><span style="font-weight: 400;">Šīs nodarbības galvenais mērķis ir izskaidrot  interneta un sociālo mediju lomu informācijas piesārņojuma radīšanā un tiešsaistes lietotāju uzticamībā.</span></p>
<p><span style="font-weight: 400;">Nodarbības sekundārais mērķis ir sniegt vadlīnijas pasniedzējiem, kuri vēlas izmantot nodarbības saturu, lai mācītu savus studentus.</span></p>
<p><span style="font-weight: 400;">Ņemot vērā šos mērķus, tiek prezentēta interneta un sociālo mediju ietekme uz informācijas piesārņojumu, kā arī norādījumi par mācību priekšmeta pasniegšanu.</span></p>
<p><span style="font-weight: 400;">Studenti, kuri būs sekmīgi apguvuši šo nodarbību, spēs:</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">izprast interneta un sociālo mediju lomu informācijas piesārņojuma veidošanā;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">atpazīt tiešsaistes lietotāju uzticamību;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">atpazīt neautentisku tiešsaistes uzvedību;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">definēt un atšķirt troļļus, botus un kiborgus;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">izprast neautentisku tiešsaistes darbību motivāciju.</span></li>
</ul>
<p><span style="font-weight: 400;">Pasniedzēji, kuri būs sekmīgi apguvuši šo nodaļu, spēs izprast kā mācīt par interneta un sociālo mediju lomu informācijas piesārņojuma radīšanā un tiešsaistes lietotāju uzticamību.</span></p>
<h2 id="nodarbibas-struktura"><strong>Nodarbības struktūra </strong></h2>
<p><span style="font-weight: 400;">Nodarbība sastāv no šādām daļām:</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">nodarbības apraksts (mērķi, satura izklāsts un mācību rezultāti),</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">nodarbības struktūra;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">vadlīnijas studentiem;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">vadlīnijas pasniedzējiem (kā sagatavoties; izmantojamās metodes; ieteikumi);</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">saturs (mācību materiāli un vingrinājumi);</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">tests;</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">informācijas resursi (izmantotie avoti, ieteicamie avoti un video).</span></li>
</ul>
<p><span style="font-weight: 400;">Galvenie nodarbības mērķi, satura izklāsts un mācību rezultāti ir raksturoti nodaļas apraksta daļā. Saturs ietver visus mācību materiālus un ar to saistītos uzdevumus. Tests sastāv no jautājumiem ar atbilžu variantiem, tas palīdzēs studentiem novērtēt savu progresu. Avoti sastāv no izmantotājiem avotiem un ieteicamajiem avotiem tālākai pētniecībai. Izmantotie avoti ir to materiālu saraksts, kas tikusi izmantoti mācību materiāla sagatavošanā. Ieteicamie avoti sastāv no papildu avotiem un video, kas ir ļoti ieteicami, lai uzzinātu vairāk par nodaļas tematu.  Vadlīnijas studentiem iekļauj instrukcijas un ieteikumus studentiem. Vadlīnijas pasniedzējiem palīdz pasniedzējiem dažādās mācību procesa fāzēs un sniedz noderīgus ieteikumus.</span></p>
<h2 id="vadlinijas-studentiem"><strong>Vadlīnijas studentiem</strong></h2>
<p><span style="font-weight: 400;">Studentiem jāizlasa teksts, jānoskatās rekomendētie video un jāizpilda vingrinājumi. Vēlams ieskatīties ieteicamajos avotos, lai uzzinātu vairāk par tematu. Pēc iepazīšanās ar nodarbības saturu, ieteicam veikt testu, lai novērtētu savu progresu. Ja nepieciešams pārskatīt mācību materiālu vēlreiz.</span></p>
<h2 class="trainer" id="vadlinijas-pasniedzejiem"><strong>Vadlīnijas pasniedzējiem</strong></h2>
<p class="trainer"><span style="font-weight: 400;">Vadlīnijas pasniedzējiem ietver ieteikumus un padomus, kā izmantot šīs nodarbības saturu mācību procesā.</span></p>
<h3 id="sagatavosanas"><strong>Sagatavošanās</strong></h3>
<p><span style="font-weight: 400;">Ieteicams sagatavot prezentāciju (PowerPoint/Prezi/Canva) par nodaļas tēmu, kas papildināta ar vizuāliem materiāliem (attēli un videoklipi) un uzskatāmiem piemēriem. Ieteicams arī pielāgot šīs nodaļas piemērus un vingrinājumus, lai tie ir piemēroti mērķauditorijai. Vietējo piemēru izvēle (konkrētā valstī) saistībā ar pašreizējām vai labi zināmām problēmām palīdz skaidrāk ilustrēt jautājumu. Tas arī palīdz pievērst studentu uzmanību. Jo pazīstamāki un populārāki būs piemēri, jo labāk tiks nodots vēstījums. Vietējās (valsts) faktu pārbaudes platformas var būt labs avots to ziņu vai gadījumu izpētei, kas jau ir pārbaudītas un marķētas.</span></p>
<h3 id="nodarbibas-uzsaksana"><strong>Nodarbības uzsākšana</strong></h3>
<p><span style="font-weight: 400;">Studentu iesaistīšanai var noderēt īss tests (3–5 jautājumi), izmantojot platformu Kahoot, vai atsevišķu jautājumu uzdošana, izmantojot Mentimeter. Jautājumi var kalpot gan kā motivējošs instruments, gan kā rīks, ar kura palīdzību iespējams apzināt studentu esošās zināšanas un izpratni par nodarbības tēmu. </span></p>
<p><span style="font-weight: 400;">Daži jautājumu piemēri: Kas ir trollis? Kas ir bots?</span></p>
<h3 id="izmantojamas-metodes"><strong>Izmantojamās metodes</strong></h3>
<p><span style="font-weight: 400;">Mācību procesā var tikt izmantotas dažādas metodes, piemēram:</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Lekcija</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Diskusija</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Darbs grupās</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Pašrefleksija</span></li>
</ul>
<h3 id="ieteikumi-pasniedzejiem"><strong>Ieteikumi pasniedzējiem</strong></h3>
<h4 id="iesildisanas"><strong>Iesildīšanās</strong></h4>
<p><span style="font-weight: 400;">Lai efektīvi iesaistītu dalībniekus mācību procesā un vienotos par to, kas tiks apgūts nodarbības laikā, tās sākumā var iesildošus uzdot jautājumus par tematu interneta un sociālo mediju loma informācijas piesārņojuma radīšanā. Tas var tikt organizēts kā grupu darbs, lūdzot studentiem apkopot un pārrunāt idejas, vai arī individuāli, aicinot katru dalībnieku uzrakstīt savas idejas uz līmlapiņas.</span></p>
<p><span style="font-weight: 400;">Aktivitātes soļi:</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Pajautājiet praktikantiem, vai viņi kādreiz ir saskārušies ar neautentiskām darbībām sociālajos medijos. Kāpēc viņi domā, ka tas nebija autentisks?</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Aiciniet praktikantus klasificēt dotos piemērus un paskaidrot, ar ko tie atšķiras.</span></li>
</ul>
<h4 id="nodarbibas-merka-paskaidrosana"><strong>Nodarbības mērķa paskaidrošana </strong></h4>
<p><span style="font-weight: 400;">Nodarbības mērķim ir  jābūt skaidram, šajā gadījumā tas ir informēt par informācijas piesārņojuma cēloni un sekām.  Pēc iesildošajiem jautājumiem būs vieglāk izskaidrot nodarbības mērķi.</span></p>
<h4 id="nodarbibas-satura-izklasts"><strong>Nodarbības satura izklāsts</strong></h4>
<p><span style="font-weight: 400;">Izklāstot nodarbības saturu, noteikti komunicējiet ar studentiem un mudiniet viņus aktīvi iesaistīties.</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Pirms sniedzat troļļu, robotu un kiborgu definīcijas, palūdziet studentiem izdomāt savu.</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Iepazīstinot ar izplatītām neautentisku darbību un kontu formām, lūdziet dalībniekus sniegt reālas dzīves piemērus. Komentējiet piemērus neatkarīgi no tā, vai tie pieder kategorijai, par kuru runājat.</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Izvēlieties reālās pasaules piemērus un iegūstiet pēc iespējas vairāk informācijas par konkrēto gadījumu. Lai pēc studentu lūguma jūs varētu paskaidrot sīkāk.</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Izvēloties piemērus, pārliecinieties, ka tie pilnībā atbilst tās kategorijas definīcijai, par kuru tiek runāts.</span></li>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">Kad vien iespējams, ļaujiet studentiem darboties praktiski.</span></li>
</ul>
<h4 id="noslegums"><strong>Noslēgums</strong></h4>
<p><span style="font-weight: 400;">Sniedziet nodarbības kopsavilkumu un uzdodiet dažus jautājumus, kas palīdzētu izcelt būtiskāko satura izklāstā.</span></p>
<p><span style="font-weight: 400;">Sekojošais jautājums var palīdzēt:</span></p>
<ul>
<li aria-level="1" style="font-weight: 400;"><span style="font-weight: 400;">   Pajautājiet praktikantiem, kā viņi reaģētu, ja viņiem būtu aizdomas par neautentisku darbību.</span></li>
</ul>
<p><span style="font-weight: 400;">Nodarbības noslēgumā pārliecinieties, vai studenti saprot, ka aiz neautentiskām darbībām slēpjas viltus lietotāju konti un slēpti mērķi (galvenokārt manipulācijas) sociālajos medijos.</span></p>
<h2 id="saturs-interneta-un-socialo-mediju-loma-informacijas-piesarnojuma-radisana"><strong>Saturs: Interneta un sociālo mediju loma informācijas piesārņojuma radīšanā</strong></h2>
<h3 id="ievads"><strong>Ievads</strong></h3>
<p><span style="font-weight: 400;">Gan interneta, gan sociālo mediju tehnoloģiju parādīšanās ir radījusi būtiskas izmaiņas informācijas veidošanā, paziņošanā un izplatīšanā. Plaši pieejami, lēti un izsmalcināti rediģēšanas un publicēšanas rīki un tehnoloģijas ir atvieglojušas satura izveidi un ātru informācijas apmaiņu. Līdz ar to šodien dezinformācija un misinformācija ir atradusi jaunu kanālu (</span><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c"><span style="font-weight: 400;">Wardle &amp; Derakhshan, 2017</span></a><span style="font-weight: 400;">, 11-12 lpp.; </span><a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf"><span style="font-weight: 400;">Tandoc, Lim &amp; Ling, 2018</span></a><span style="font-weight: 400;">, 139. lpp.).</span></p>
<p><span style="font-weight: 400;">Mūsdienās ir mainījies ne tikai ziņu izplatīšanas veids, bet arī to izskats. Tvīts, kura garums nepārsniedz 280 rakstzīmes, tagad tiek uzskatīts par ziņu, un Twitter kļuva par  īpašu platformu jaunāko ziņu ātrai izplatīšanai. Facebook ir vēl viena sociālo mediju platforma, kas ir kļuvusi par vietu, kur lietotāji veido, patērē un apmainās ar ziņām, kā arī personīgiem atjauninājumiem un fotoattēliem (</span><a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf"><span style="font-weight: 400;">Tandoc, Lim &amp; Ling, 2018</span></a><span style="font-weight: 400;">, 139. lpp.).</span></p>
<p><span style="font-weight: 400;">Visas tiešsaistes platformas, īpaši sociālie mediji, nodrošina iespēju nežurnālistiem sasniegt masu auditoriju, citiem vārdiem sakot, tās sniedz iespējas pilsoniskajai žurnālistikai. Mūsdienās nežurnālisti ir sākuši nodarboties ar žurnālistikas aktivitātēm (</span><a href="https://journals.sagepub.com/doi/full/10.1177/1464884911415973"><span style="font-weight: 400;">Robinson &amp; DeShano, 2011</span></a><span style="font-weight: 400;">, 965. lpp.). Viņi ievieto informāciju, fotoattēlus un video par jaunākajām ziņām, kurām ir bijuši liecinieki, savos sociālo mediju kontos (</span><a href="https://www.academia.edu/40668891/The_trouble_with_twittering_integrating_social_media_into_mainstream_news"><span style="font-weight: 400;">Jewitt, 2009</span></a><span style="font-weight: 400;">, 231. lpp.).</span></p>
<p><span style="font-weight: 400;">Sociālie mediji veido mediju ainavu vairākos veidos. Pirmkārt, saturs no dažādiem avotiem tiek rādīts vienā vietā, lietotājiem vairs nav jāizvēlas ziņu avots; tā vietā viņi izvēlas pašu stāstu (</span><a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406"><span style="font-weight: 400;">Messing &amp; Westwood, 2014</span></a><span style="font-weight: 400;">, 1044. lpp.). Informācijas avots kļūst neskaidrs, jo ziņas/informācija ātri pārvietojas no vienas personas/kanāla uz citu (</span><a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf"><span style="font-weight: 400;">Tandoc, Lim &amp; Ling, 2018</span></a><span style="font-weight: 400;">, 139. lpp.). Otrkārt, satura atlasi nosaka apstiprinājumi un sociālie ieteikumi (</span><a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406"><span style="font-weight: 400;">Messing &amp; Westwood, 2014</span></a><span style="font-weight: 400;">, 1044. lpp.). Izplatīšanā liela nozīme ir popularitātei. Atzīmes “patīk”, kopīgošana vai komentāri izraisa turpmākas atzīmes “patīk”, kopīgošanu vai komentārus (</span><a href="https://www.tandfonline.com/doi/full/10.1080/13691180801999027"><span style="font-weight: 400;">Thorson, 2008</span></a><span style="font-weight: 400;">, 475. lpp.).</span></p>
<p><span style="font-weight: 400;">Turklāt, atšķirībā no tradicionālajiem ziņu medijiem, manipulēta satura kopīgošanai sociālajos medijos nav ētikas kodeksa (</span><a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf"><span style="font-weight: 400;">Tandoc, Lim &amp; Ling, 2018</span></a><span style="font-weight: 400;">, 144.–145. lpp.). Informācijas pārbaude dažādos formātos, piemēram, fotoattēlos un videoklipos,  sagādā </span><span style="font-weight: 400;">grūtības, turklāt tam nepieciešamas zināšanas. </span></p>
<p><span style="font-weight: 400;">Misinformācija un dezinformācija pastāv jau pirms drukātās preses, taču internets ir ļāvis viltus ziņām, sazvērestības teorijām un pārspīlējumiem izplatīties ātrāk un tālāk nekā jebkad agrāk (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">).</span></p>
<h3 id="tiessaistes-lietotaju-uzticamiba"><strong>Tiešsaistes lietotāju uzticamība</strong></h3>
<p><span style="font-weight: 400;">Tiešsaistes kopienu lietotāju uzticamība ir vēl viena problēma (</span><a href="https://www.sciencedirect.com/science/article/pii/S138912861200179X"><span style="font-weight: 400;">Ortega, Troyano, Cruz, Vallejo &amp; Enriquez, 2012</span></a><span style="font-weight: 400;">, 2884. lpp.). Visi instrumenti, kā arī talants tos izmantot, šodien ir nopērkami. Ikviens var iegādāties tūkstošiem sociālo mediju kontu vai miljoniem e-pasta adrešu un nolīgt rakstniekus vai publicētājus, kas palīdzēs masveidā izplatīt jebkuru vēstījumu vai ideoloģiju (</span><a href="https://medium.com/the-walkley-magazine/you-cant-sell-news-for-what-it-costs-to-make-7a4def964ffa"><span style="font-weight: 400;">Filloux, 2017</span></a><span style="font-weight: 400;">).</span></p>
<p><span style="font-weight: 400;">Pastāv uzņēmumi un privātpersonas, kas par saprātīgām cenām atklāti pārdod Twitter, Facebook un YouTube sekotājus/abonentus un to iesaisti, retvītus un dalīšanos (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">).</span></p>
<center>
<p><img src="../img/module_04/figure_01.jpg"/></p>
<p><span style="font-weight: 400;">Avots: </span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a></p>
</center>
<p><span style="font-weight: 400;">Sociālie mediji arvien vairāk tiek izmantoti, lai pastiprinātu nepatiesus apgalvojumus, kā arī polarizētu cilvēkus par strīdīgiem jautājumiem. Kiborgi, troļļi un boti veicina informācijas piesārņošanu tiešsaistē, piepildot internetu ar dezinformāciju (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">).</span></p>
<center>
<p><img src="../img/module_04/figure_03.jpg"/></p>
<p><span style="font-weight: 400;">Avots: </span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018.gada 5.novembrī</span></a></p>
</center>
<h4 id="trolli-un-trollu-fermas"><strong>Troļļi un troļļu fermas</strong></h4>
<p><span style="font-weight: 400;">Vārds “trollis” attiecināms uz personām, kuras tīši ierosina tiešsaistes konfliktus vai aizskar citus lietotājus uzmanības novēršanai vai, lai radītu šķelšanos tiešsaistes kopienā vai sociālajā tīklā, ievietojot tajā mulsinošus vai nesaistītus ierakstus (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">; </span><a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf"><span style="font-weight: 400;">Wardle, 2018</span></a><span style="font-weight: 400;">). Troļļu mērķis ir izprovocēt citus uz emocionālu reakciju un izjaukt diskusijas, dažreiz viņu pašu izklaidei un dažreiz koordinētas kampaņas ietvaros (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">). Organizētu interneta troļļu grupu sauc par troļļu fermu jeb troļļu fabriku.</span></p>
<p><span style="font-weight: 400;">Troļļi dažreiz saņem samaksu par informācijas izplatīšanu. Tie var radīt būtisku (negatīvu/pozitīvu) ietekmi uz tiešsaistes kopienām (</span><a href="https://www.semanticscholar.org/paper/Battling-the-Internet-water-army%3A-Detection-of-paid-Chen-Wu/26d0d7942e4c0cb24abef3abea6d763d4da668f5"><span style="font-weight: 400;">Chen, Wu, Srinivasan &amp; Zhang, 2013</span></a><span style="font-weight: 400;">).  Šādi veidota propaganda bieži vien ir balstīta faktos, taču ietver neobjektivitāti, kas veicina konkrētu viedokli, perspektīvu vai reklamē produktu. Šādas ziņu un komentāru sajaukšanas mērķis bieži ir pārliecināt, nevis informēt (</span><a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf"><span style="font-weight: 400;">Tandoc, Lim &amp; Ling, 2018</span></a><span style="font-weight: 400;">, 147. lpp.).</span></p>
<p><span style="font-weight: 400;">Piemēram, </span><em><span style="font-weight: 400;">Interneta ūdens armija </span></em><span style="font-weight: 400;">(Internet Water Army) no Ķīnas ir grupa, kurai maksā par tiešsaistes komentāru ievietošanu internetā ar noteiktu. Šos cilvēkus pieņem darbā uzņēmumi, lai tiešsaistes platformās reklamētu pozitīvas ziņas par saviem produktiem un negatīvas ziņas par konkurentiem (</span><a href="https://en.wikipedia.org/wiki/Internet_Water_Army"><span style="font-weight: 400;">Internet Water Army, 2020</span></a><span style="font-weight: 400;">). Savukārt </span><em><span style="font-weight: 400;">50 centu partija/armija</span></em><span style="font-weight: 400;"> (50 Cent Party/Army) ir komentētāju grupa, ko Ķīnas varas iestādes nolīgušas, lai manipulētu ar sabiedrisko domu Ķīnas komunistiskās partijas labā. Hārvardas pētījuma rezultāti liecina, ka Ķīnas valdība katru gadu izveido aptuveni 448 miljonus sociālo mediju ierakstu (</span><a href="https://gking.harvard.edu/files/gking/files/how_the_chinese_government_fabricates_social_media_posts_for_strategic_distraction_not_engaged_argument.pdf"><span style="font-weight: 400;">King, Pan &amp; Roberts, 2017</span></a><span style="font-weight: 400;">; </span><a href="https://en.wikipedia.org/wiki/50_Cent_Party"><span style="font-weight: 400;">50 Cent Party, 2020</span></a><span style="font-weight: 400;">).</span></p>
<center>
<p><img src="../img/module_04/figure_02.jpg"/></p>
<p><span style="font-weight: 400;">Avots: </span><a href="https://www.ft.com/content/b4f27934-944a-11e8-b67b-b8205561c3fe"><span style="font-weight: 400;">Financial Times: Yang, 2018. gada 1. augusts</span></a></p>
</center>
<p><span style="font-weight: 400;">Pēdējā laikā interneta troļļu izmantošana viedokļu manipulēšanai ir kļuvusi par ierastu praksi. Populārs troļļošanas veids ir strīdīgu komentāru rakstīšana no viltus profiliem par konkrētu tēmu. Mērķis ir par katru cenu uzvarēt strīdā, to parasti pavada neprecīza un maldinoša informācija (</span><a href="https://www.aclweb.org/anthology/R15-1058.pdf"><span style="font-weight: 400;">Mihaylov, Koychev, Georgiev &amp; Nakov, 2015</span></a><span style="font-weight: 400;">, 443. lpp.).</span></p>
<h5 id="piemers-bils-geitss-trollu-merkis"><strong>Piemērs: Bils Geitss - troļļu mērķis</strong></h5>
<p><span style="font-weight: 400;">Sociālo mediju uzbrukumi Bilam Geitsam (Bill Gates) pastiprinājās 2020.gada aprīlī pēc tam, kad viņš Instagram ievietoja video, kurā viņš pie loga izkāra zīmi “Paldies veselības aprūpes darbiniekiem”. Nākamo dienu laikā šis ieraksts saņēma simtiem tūkstošu komentāru, kas viņu saistīja ar dažādām sazvērestības teorijām, kas saistītas ar vakcīnām, Pasaules Veselības organizāciju (PVO) un implantētām mikroshēmām. Uzbrukumi pastiprinājās nākamajā nedēļā pēc tam, kad viņš kritizēja Trampa administrācijas lēmumu apturēt finansējumu PVO. 24 stundu laikā pēc Bila Geitsa komentāriem viņa Twitter kontu pieminēja vismaz 270 000 reižu, kas ir 30 reizes vairāk kā vidēji. Tie bija galvenokārt dusmīgi prezidenta Trampa atbalstītāji (</span><a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/"><span style="font-weight: 400;">Stronder, 2020. gada 21. maijs</span></a><span style="font-weight: 400;">).</span></p>
<center>
<table class="table table-md">
<tbody>
<tr>
<td><center><img src="../img/module_04/figure_05.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_04.jpg"/><br><br/><img src="../img/module_04/figure_07.jpg"/></br></center></td>
</tr>
<tr>
<td><center>
<p><span style="font-weight: 400;">Avots: </span><a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/"><span style="font-weight: 400;">Schlosser, 2020. gada 15. aprīlis</span></a><span style="font-weight: 400;">.</span></p>
</center></td>
<td><center>
<p><span style="font-weight: 400;">Avots: </span><a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938"><span style="font-weight: 400;">Seetharaman, 2020. gada 17. aprīlis.</span></a></p>
</center></td>
</tr>
</tbody>
</table>
</center>
<h5 id="piemers-trolli-pirms-meginaja-izraisit-nesaskanas-starp-kanadiesiem-2017-gada-velesanam"><strong>Piemērs: troļļi pirms mēģināja izraisīt nesaskaņas starp kanādiešiem  2017. gada vēlēšanām </strong></h5>
<p><span style="font-weight: 400;">Pētījumā, kas tika veikts no 2017. gada janvāra līdz februārim, izanalizējot 18 533 tvītus, atklājās, ka troļļi pirms 2017. gada vēlēšanām mēģināja izraisīt šķelšanos starp kanādiešiem. Pēc apšaudes Kvebekas mošejā 2017. gadā Twitter tika ievietotas viltus ziņas un islamofobiski paziņojumi (</span><a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144"><span style="font-weight: 400;">Rawi &amp; Jiwani, 2019. gada 23. jūlijs</span></a><span style="font-weight: 400;">).</span></p>
<center>
<p><img src="../img/module_04/figure_06.jpg"/></p>
<p><span style="font-weight: 400;">Avots: </span><a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144"><span style="font-weight: 400;">Al-Rawi &amp; Jiwani, 2019. gada 23. jūlijs</span></a><span style="font-weight: 400;">  </span></p>
</center>
<p><span style="font-weight: 400;">Trollis atšķirībā no robota ir īsts lietotājs, savukārt robotprogrammatūra (boti) ir automatizēta. Troļļošana kā darbība neaprobežojas tikai ar troļļiem vien. Troļļi dažreiz izmanto arī robotprogrammatūras, lai pastiprinātu savus ziņojumus. Tādējādi botus var izmantot troļļošanas nolūkos (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">).</span></p>
<h4 id="zeku-lellu-konti-sock-puppet-accounts"><strong>Zeķu leļļu konti / Sock Puppet Accounts</strong></h4>
<p><span style="font-weight: 400;">Zeķu lelle ir viltus konta veids. Lai gan daži lietotāji izmanto anonīmus kontus, lai vienkārši izvairītos no sevis identificēšanas, zeķu leļļu kontu īpašnieki izmanto tos, lai uzbruktu kritiķiem vai slavētu sevi (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">).</span></p>
<h5 id="piemers-asv-senatora-zeku-lelles-konts"><strong>Piemērs: ASV senatora zeķu lelles konts</strong></h5>
<p><span style="font-weight: 400;">ASV Jūtas senators Mits Romnijs(Mitt Romney) atzina, ka viņam ir slepens Twitter konts ar nosaukumu “Pierre Delecto”, ko viņš izmantoja, lai aizstāvētu sevi pret kritiku (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Kleper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">).</span></p>
<center>
<table class="table table-md">
<tbody>
<tr>
<td><center><img src="../img/module_04/figure_09.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_08.jpg"/></center></td>
</tr>
</tbody>
</table>
</center><center>
<p><span style="font-weight: 400;">Avots: </span><a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html"><span style="font-weight: 400;">Feinberg, 2019. gada 20. oktobris</span></a></p>
</center>
<h4 id="boti-un-bottikli"><strong>Boti un bottīkli</strong></h4>
<p><span style="font-weight: 400;">Bots ir automatizēts sociālo mediju konts, ko vada algoritms, nevis reāla persona. Citiem vārdiem sakot, robots ir paredzēts, lai izveidotu ziņas bez cilvēka iesaistes. Trīs galvenie botu indikatori ir anonimitāte, augsts aktivitātes līmenis un konkrētu lietotāju, tēmu vai mirkļbirku paplašināšana (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">). Autentiski Twitter lietotāji bieži publicē ziņas dažas reizes dienā par dažādām tēmām, turpretī robotprogrammatūras tvītos simtiem reižu dienā un bieži vien tikai par konkrētu tēmu. Viņi, visticamāk, pārpublicēs saturu, nevis izveidos kaut ko oriģinālu (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">). Boti var izmantot atsauces un publicēt saturu, kas galu galā var ietekmēt dažādu sociālo mediju platformu algoritmus (</span><a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/"><span style="font-weight: 400;">Stronder, 2020. gada 21. maijs</span></a><span style="font-weight: 400;">).</span></p>
<p><span style="font-weight: 400;">Ja konts raksta atsevišķas ziņas un komentē, atbild vai kā citādi mijiedarbojas ar citu lietotāju ziņām, kontu nevar klasificēt kā robotu. Boti pārsvarā ir atrodami Twitter un citos sociālajos tīklos, kas ļauj lietotājiem izveidot vairākus kontus (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">).</span></p>
<p><span style="font-weight: 400;">Dezinformācijas kampaņās botus var izmantot, lai pievērstu uzmanību maldinošiem stāstiem, lai pārpludinātu platformu tendenču sarakstus un radītu ilūziju par publisku diskusiju un atbalstu (</span><a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf"><span style="font-weight: 400;">Wardle, 2018</span></a><span style="font-weight: 400;">). Dienvidkalifornijas universitātes pētnieku pētījumā tika analizēti ar ASV vēlēšanām saistīti tvīti, kas tika veikti 2016. gada septembrī un oktobrī, un konstatēts, ka vienu no katriem pieciem bija veicis bots (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, February 7, 2020</span></a><span style="font-weight: 400;">).</span></p>
<h5 id="piemers-pandemijas-uzliesmojuma-laika-aptuveni-45-tvitu-sutija-roboti"><strong>Piemērs: pandēmijas uzliesmojuma laikā aptuveni 45% tvītu sūtīja roboti</strong></h5>
<p><span style="font-weight: 400;">Pēc Kārnegija Melona universitātes pētnieku domām, gandrīz puse Twitter kontu, kas sociālo mediju platformā izplata ziņas par koronavīrusa pandēmiju, visticamāk, ir robotprogrammatūras. Pandēmijas uzliesmojuma sākumā pētnieki izpētīja vairāk kā 200 miljonus tvītu, kas apsprieda vīrusu un atklāja, ka aptuveni 45% no tiem tika nosūtīti no kontiem, kas vairāk uzvedas kā roboti. Pētnieki novēroja vairāk kā 100 neprecīzu COVID-19 stāstu veidus, piemēram, tādus, kas saistīti ar iespējamiem ārstēšanas veidiem. Boti arī dominēja sarunās par mājsēdes rīkojumu izbeigšanu un "Amerikas atvēršanu" (</span><a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html"><span style="font-weight: 400;">Young, 2020. gada 27. maijs</span></a><span style="font-weight: 400;">).</span></p>
<center>
<table class="table table-md">
<tbody>
<tr>
<td><center><img src="../img/module_04/figure_12.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_10.jpg"/></center></td>
</tr>
<tr>
<td><center>
<p><span style="font-weight: 400;">Avots: </span><a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html"><span style="font-weight: 400;">Young, 2020. gada 27. maijs</span></a></p>
</center></td>
<td><center>
<p><span style="font-weight: 400;">Avots: </span><a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T"><span style="font-weight: 400;">Bensons, 2020. gada 24. aprīlis</span></a></p>
</center></td>
</tr>
</tbody>
</table>
</center>
<p><span style="font-weight: 400;">Botu tīkls ir robotu kontu tīkls, ko pārvalda viena un tā pati persona vai grupa. Personas, kas pārvalda robottīklus, kuriem pirms izvietošanas ir nepieciešama cilvēka sākotnējā palīdzība, sauc par robotu ganiem vai ganiem. Bottīkla mērķis ir panākt, lai mirkļbirka, lietotājs vai atslēgvārds izskatītos vairāk apspriests (pozitīvs vai negatīvs) vai populārs, nekā tas patiesībā ir. Boti ir vērsti uz sociālo mediju algoritmiem, lai ietekmētu tendenču sadaļu, kas savukārt pakļautu nenojaušām lietotāju sarunām, ko pastiprina robotprogrammatūra. Bottīkli reti vēršas pret cilvēkiem, un, kad tas tiek darīti, tie ir surogātpasta vai vispārīga viņu aizskaršana, nevis aktīvi mēģinājumi mainīt viņu viedokli vai politiskos uzskatus (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">).</span></p>
<h5 id="piemers-pirms-malaizijas-velesanam-tika-konstatetas-botu-darbibas"><strong>Piemērs: pirms Malaizijas vēlēšanām tika konstatētas botu darbības</strong></h5>
<p><span style="font-weight: 400;">Pirms vēlēšanām Malaizijā </span><em><span style="font-weight: 400;">DFRLab</span></em><span style="font-weight: 400;"> (Digitālās kriminālistikas pētījumu laboratorija) atrada 22 000 robotprogrammu, kas visas izmantoja vienādu runas modeli. Katrs robots izmantoja divas mirkļbirkas, kas bija mērķētas uz opozīcijas koalīciju, kā arī atzīmēja 13–16 reālus lietotājus, lai mudinātu viņus iesaistīties sarunā (</span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a><span style="font-weight: 400;">).</span></p>
<center><img src="../img/module_04/figure_11.jpg"/>
<p><span style="font-weight: 400;">Avots: </span><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/"><span style="font-weight: 400;">Barojan, 2018. gada 5. novembris</span></a></p>
</center>
<h4 id="kiborgi"><strong>Kiborgi</strong></h4>
<p><span style="font-weight: 400;">Kiborgs ir hibrīdkonts, kas apvieno robota nenogurdināmību un cilvēka smalkumu. Kiborga konti ir tie, kuros cilvēks periodiski pārņem robota kontu, lai atbildētu uz citiem lietotājiem un publicētu oriģinālo saturu. Tie ir dārgāki, un to darbība ir laikietilpīgāka, taču tos ir daudz grūtāk atklāt (</span><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94"><span style="font-weight: 400;">Klepper, 2020. gada 7. februāris</span></a><span style="font-weight: 400;">).</span></p>
<h2 id="vingrinajumi">Vingrinājumi</h2>
<p><strong>Trollis</strong><span style="font-weight: 400;"> ir īsts lietotājs, savukārt </span><strong>bots</strong><span style="font-weight: 400;"> ir automatizēts. </span><strong>Botu</strong><span style="font-weight: 400;"> vada algoritms, nevis reāla persona. </span><strong>Bots</strong><span style="font-weight: 400;"> ir paredzēts, lai publicētu ziņas bez cilvēka iejaukšanās, savukārt </span><strong>kiborgs</strong><span style="font-weight: 400;"> ir hibrīdkonts, kas apvieno robotu un reālu personu.</span></p>
<h2 id="tests">Tests</h2>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="257" src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=68" title="Essential MOOC-LV: 1. daļa - 4. nodarbība - 1. tests" width="958"></iframe></p>
<h2 id="izmantotie-avoti">Izmantotie avoti</h2>
<p><a href="https://en.wikipedia.org/wiki/50_Cent_Party" rel="noopener" target="_blank">50 Cent Party. (2020).</a> In Wikipedia.</p>
<p><a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" rel="noopener" target="_blank">Al-Rawi, A. &amp; Jiwani, J. (July 23, 2019).</a> Russian Twitter trolls stoke anti-immigrant lies ahead of Canadian election. The Conversation.</p>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" rel="noopener" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.</p>
<p><a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" rel="noopener" target="_blank">Benson, T. (April, 24, 2020).</a> Trolls and bots are flooding social media with disinformation encouraging states to end quarantine. Insider.</p>
<p><a href="https://www.semanticscholar.org/paper/Battling-the-Internet-water-army%3A-Detection-of-paid-Chen-Wu/26d0d7942e4c0cb24abef3abea6d763d4da668f5" rel="noopener" target="_blank">Chen, C., Wu, K., Venkatesh, S. &amp; Zhang, X. (2013).</a> Battling the Internet Water Army: Detection of hidden paid posters. Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. Niagara, Canada: ACM.</p>
<p><a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" rel="noopener" target="_blank">Feinberg, A. (October 20, 2019).</a> This sure looks like Mitt Romney’s secret Twitter account (Update: It is): Meet “Pierre Delecto”. The Slate.<a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" rel="noopener" target="_blank"> https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html</a></p>
<p><a href="https://medium.com/the-walkley-magazine/you-cant-sell-news-for-what-it-costs-to-make-7a4def964ffa" rel="noopener" target="_blank">Filloux, F. (2017).</a> You can’t sell news for what it costs to make. The Walkley Magazine on Medium.</p>
<p><a href="https://en.wikipedia.org/wiki/Internet_Water_Army" rel="noopener" target="_blank">Internet Water Army. (2020).</a> In Wikipedia.</p>
<p><a href="https://www.academia.edu/40668891/The_trouble_with_twittering_integrating_social_media_into_mainstream_news" rel="noopener" target="_blank">Jewitt, R. (2009).</a> The trouble with twittering: Integrating social media into mainstream news. International Journal of Media &amp; Cultural Politics, 5(3), 233–246. doi:10.1386/- macp.5.3.233_3</p>
<p><a href="https://gking.harvard.edu/files/gking/files/how_the_chinese_government_fabricates_social_media_posts_for_strategic_distraction_not_engaged_argument.pdf" rel="noopener" target="_blank">King, G., Pan, J. &amp; Roberts, M. E. (2017).</a> How the Chinese government fabricates Social Media posts for strategic distraction, not engaged argument. American Political Science Review, 111(3), 484-501. DOI:<a href="http://dx.doi.org/10.1017/S0003055417000144" rel="noopener" target="_blank"> 10.1017/S0003055417000144 </a></p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" rel="noopener" target="_blank">Klepper, D. (February 7, 2020).</a> Cyborgs, trolls and bots: A guide to online misinformation.</p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406" rel="noopener" target="_blank">Messing, S., &amp; Westwood, S. J. (2014).</a> Selective exposure in the age of social media: Endorsements trump partisan source affiliation when selecting news online. Communication Research, 41(8), 1042-1063.</p>
<p><a href="https://www.aclweb.org/anthology/R15-1058.pdf" rel="noopener" target="_blank">Mihaylov, T., Koychev, I., Georgiev, G.D. &amp; Nakov, P. (2015).</a> Exposing paid opinion manipulation trolls. In: Proceedings of Recent Advances in Natural Language Processing (pp. 443–450), Hissar, Bulgaria, Sep 7–9 2015.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S138912861200179X" rel="noopener" target="_blank">Ortega, F. J., Troyano, J., Cruz, F., Vallejo, C. &amp; Enriquez, F. (2012).</a> Propagation of trust and distrust for the detection of trolls in a social network. Computer Networks. 56. 2884-2895. 10.1016/j.comnet.2012.05.002.</p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1464884911415973" rel="noopener" target="_blank">Robinson, S., &amp; DeShano, C. (2011).</a> ‘Anyone can know’: Citizen journalism and the interpretive community of the mainstream press. Journalism, 12(8), 963–982. doi:10.1177/1464884911415973.</p>
<p><a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" rel="noopener" target="_blank">Seetharaman, D. (April 17, 2020).</a> Bill Gates is targeted by Social-Media mobs. The Wall Street Journal.</p>
<p><a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" rel="noopener" target="_blank">Schlosser, K. (April 15, 2020).</a> Bill Gates calls Trump’s freeze on WHO funding ‘dangerous’ and tweet draws a viral response. GeekWire.</p>
<p><a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" rel="noopener" target="_blank">Stronder (May 21, 2020).</a> Fighting disinformation, trolls, and bots on social media during COVID-19.</p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143" rel="noopener" target="_blank">Tandoc, E.C., Lim, Z. W. &amp; Ling, R. (2018).</a> Defining “fake news”. Digital Journalism, 6(2), 137-153. DOI: 10.1080/21670811.2017.1360143</p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/13691180801999027" rel="noopener" target="_blank">Thorson, E. (2008).</a> Changing patterns of news consumption and participation. Information, Communication and Society, 11(4), 473–489. doi:10.1080/13691180801999027.</p>
<p><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" rel="noopener" target="_blank">Wardle, C. &amp; Derakhshan, H. (2017).</a> Information disorder: Toward an interdisciplinary framework for research and policymaking. The Council of Europe.</p>
<p><a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf" rel="noopener" target="_blank">Wardle, C. (2018).</a> The Essential Glossary.</p>
<p><a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" rel="noopener" target="_blank">Young, V. A. (May 27, 2020)</a>. Nearly half of the Twitter accounts discussing 'reopening America' may be bots. Carnegie Mellon University News.</p>
<p><a href="https://www.ft.com/content/b4f27934-944a-11e8-b67b-b8205561c3fe" rel="noopener" target="_blank">Yang, Y. (August 1, 2018). </a>China’s battle with the internet water army.</p>
<h2 id="ieteicamie-avoti">Ieteicamie avoti</h2>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" rel="noopener" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" rel="noopener" target="_blank"> https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/</a></p>
<p><a href="https://medium.com/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c" rel="noopener" target="_blank">DFR Lab. (August 29, 2017).</a> #BotSpot: Twelve Ways to Spot a Bot: Some tricks to identify fake Twitter accounts.</p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" rel="noopener" target="_blank">Klepper, D. (February 7, 2020). </a>Cyborgs, trolls and bots: A guide to online misinformation.</p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" rel="noopener" target="_blank">Wild, J. &amp; Godart, C. (2020).</a> Spotting bots, cyborgs and inauthentic activity. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" rel="noopener" target="_blank">Zadrozny, B. (2020).</a> Investigating social media accounts. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<h2 id="ieteicamie-video">Ieteicamie video</h2>
<p><a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" rel="noopener" target="_blank">Associated Press. (2020).</a> Cyborgs, trolls and bots: AP explains online misinformation<a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" rel="noopener" target="_blank"> </a></p>
</div>
<!--/span--></div>
<!--/row--></div>
<!--/.fluid-container-->
<!-- Le javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="../js/jquery-1.8.3.min.js"></script>
<script src="../js/jquery-ui-1.9.1.custom.min.js"></script>
<script src="../js/bootstrap.bundle.min.js"></script>
<script src="../js/jquery.tocify.js"></script>
<script src="../js/prettify.js"></script>
<script src="../js/user_control.js"></script>
<script>
        $(function() {

            var toc = $("#toc").tocify({
              selectors: "h2,h3,h4,h5"
            }).data("toc-tocify");

            prettyPrint();
            $(".optionName").popover({ trigger: "hover" });

        });
    </script>
</body>
</html>