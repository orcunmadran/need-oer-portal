<!DOCTYPE html>

<html lang="tr">
<head>
<meta charset="utf-8"/>
<title>Modül 6: Algoritmalar Çağı</title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="This course is designed to help individuals to become smart consumers of news and informed participants in civic life." name="description"/>
<meta content="ESSENTIAL Projesi Türkiye Ekibi" name="author"/>
<!-- Le styles -->
<link href="../css/bootstrap.css" rel="stylesheet"/>
<link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/black-tie/jquery-ui.css" rel="stylesheet"/>
<link href="../css/jquery.tocify.css" rel="stylesheet"/>
<link href="../css/prettify.css" rel="stylesheet" type="text/css">
<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<!-- Le fav icon -->
<link href="../assets/ico/favicon.ico" rel="shortcut icon"/>
<style>
    body {
      padding-top: 20px;
    }
    p {
      font-size: 16px;
    }
    .headerDoc {
      color: #005580;
    }

@media (max-width: 767px) {
    #toc {
        position: relative;
        width: 100%;
        margin: 0px 0px 20px 0px;
    }
}
    </style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VFJPMP12NF"></script>
<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
 		gtag('js', new Date());

 		gtag('config', 'G-VFJPMP12NF');
	</script>
</link></head>
<body>
<div class="container-fluid">
<div class="row-fluid">
<div class="span3">
<div id="toc">
<center>
<br/>
<code class="trainee">Öğrenen Sürümü</code>
<code class="trainer">Eğitici Sürümü</code>
<code class="select"><a href="?userType=trainee">Öğrenen Sürümü</a></code>
<code class="select"><a href="?userType=trainer">Eğitici Sürümü</a></code>
<a href="#top"><img src="../img/index/essential_logo.jpg" width="75%"/></a>
<p><a class="btn btn-secondary btn-small" href="index.html">Ana Sayfa</a></p>
</center>
</div><!--/.well -->
</div><!--/span-->
<div class="span9">
<div class="hero-unit">
<h1 id="modul-6-algoritmalar-cagi">Modül 6: Algoritmalar Çağı</h1>
</div>
<!--/CONTENT-->
<h2 id="modulun-tanimi">Modülün Tanımı</h2>
<p>Bu Modülün temel amacı, algoritmalar, algoritmaların nasıl çalıştığı, insanları ve toplumları nasıl etkiledikleri ile otomatik karar vermenin faydaları ve sonuçları hakkında farkındalık yaratmaktır.</p>
<p class="trainer">İkincil amaç, bu Modülün içeriğini başkalarını eğitmek için kullanmak isteyen eğitmenlere rehberlik etmektir.</p>
<p class="trainer">Bu modülde bu amaçlarla algoritmaların nasıl çalıştığı, insanlar, toplumlar ve günlük yaşam üzerindeki olası etkileri, neden dikkatli bir şekilde ele alınmaları ve kullanılmaları gerektiği ve konunun nasıl öğretileceğine ilişkin yönergeler ele alınmaktadır.</p>
<p>Bu modülü başarıyla tamamlayanlar şunları yapabilirler:</p>
<ul>
<li>algoritmaların ne olduğunu ve nasıl çalıştıklarını anlar ve açıklayabilir</li>
<li>algoritmaların insanları ve toplumları nasıl etkilediğini bilir</li>
<li>algoritmaların artılarını ve eksilerini anlar ve açıklayabilir</li>
<li>algoritmalar, haberler ve haber akışları arasındaki bağlantıyı anlar</li>
<li>filtre balonları ve yankı odalarının nasıl oluştuğunu anlar</li>
</ul>
<p class="trainer">Ek olarak, bu modülü başarıyla tamamlayan eğitmenler, konuyla ilgili eğitim yönergelerini anlarlar.</p>
<h2 id="modulun-yapisi">Modülün Yapısı</h2>
<p>Bu Modül aşağıdaki bölümlerden oluşur:</p>
<ul>
<li>Amaç, İçeriğin Tanımı ve Öğrenme Çıktıları</li>
<li>Modülün Yapısı</li>
<li>Öğrenenler için Yönerge</li>
<li class="trainer">Eğitmenler için Yönerge (hazırlık, kullanılacak yöntemler ve eğitmenler için ipuçları)</li>
<li>İçerik (çalışma materyalleri ve alıştırmalar)</li>
<li>Test</li>
<li>Kaynakça (yararlanılan kaynaklar ve önerilen kaynaklar ile videolar)</li>
</ul>
<p>Modülün ana hedefleri, içerik ve öğrenme çıktıları Modülün Tanımı bölümünde açıklanmıştır. Öğrenenler için Yönerge, öğrenenler için yönlendirme ve önerileri içerir. <span class="trainer">Eğitmenler için Yönerge, eğitimin farklı aşamalarında eğitmenlere rehberlik eder ve konuyu öğretirken faydalı olabilecek ipuçları sağlar.</span> İçerik, tüm çalışma materyallerini ve ilgili alıştırmaları içerir. Test, katılımcıların kendilerini ve ilerlemelerini test edebilmeleri için hazırlanmıştır. Genellikle çoktan seçmeli veya doğru/yanlış sorularından oluşur. Kaynakça, yararlanılan kaynaklar ve önerilen kaynaklar şeklinde iki bileşenden oluşur. İçerik hazırlanırken yararlanılan ve atıf yapılan kaynaklar Kaynakça başlığı altında listelenmiştir. Ek Kaynakça, konuyla ilgili daha fazla bilgi edinmek isteyenler için okunması önerilen kaynakların ve izlenmesi önerilen videoların bir listesinden oluşur.</p>
<h2 id="ogrenenler-icin-yonerge">Öğrenenler için Yönerge</h2>
<p>Öğrenenlerden içeriği dikkatle okumaları, önerilen videoları izlemeleri ve alıştırmaları yapmaları beklenmektedir. Daha fazla bilgi gereksinimi duydukları konularda kaynakçalarda listelenen kaynaklara başvurabilirler. İçerik üzerindeki çalışmalarını tamamladıktan sonra, ilerlemelerini değerlendirmek için modül sonundaki testi yapmaları önerilir. Test sonuçlarına göre gerekirse çalışma materyali yeniden gözden geçirilebilir.</p>
<h2 class="trainer" id="egitmenler-icin-yonerge">Eğitmenler için Yönerge</h2>
<p class="trainer">Bu bölüm, ele alınan konunun nasıl öğretileceğine ve Modül içeriğinin bu amaçla nasıl kullanılabileceğine ilişkin eğiticilere yönelik öneriler ve ipuçları içerir.</p>
<span class="trainer">
<h3 id="hazirlik">Hazırlık</h3>
<p>Eğitim başlamadan önce görsel materyallerle (resim ve video klipler) zenginleştirilmiş bir sunum (PowerPoint/Prezi/Canva) hazırlanması önerilir. Örneğin, farklı yerlerde bulunan bireylerin aynı arama motorunda aynı konuda yaptığı aramanın sonuçları gösterilebilir. Ayrıca gerçek zamanlı bir demonstrasyon da yapılabilir.</p>
<h3 id="baslarken">Başlarken</h3>
<p>Konuya ısındırmak amacıyla başlangıçta Kahoot veya Mentimeter gibi araçlar kullanılarak katılımcılara konuyla ilgili genel ve kısa bazı sorular (3 ile 5 soru) yöneltilebilir. Böyle bir başlangıç katılımcıların konuyla ilgili mevcut bilgi düzeyleri hakkında bilgi de sağlayacaktır.</p>
<h3 id="kullanilacak-yontemler">Kullanılacak Yöntemler</h3>
<p>Eğitim sırasında çeşitli öğretim yöntemleri bir arada kullanılabilir:</p>
<ul>
<li>Ders anlatma</li>
<li>Tartışma</li>
<li>Grup çalışması</li>
<li>Kendini yansıtma</li>
</ul>
<h3 id="egitmenler-icin-ipuclari">Eğitmenler için İpuçları</h3>
<h4 id="isinma">Isınma</h4>
<p>Katılımcıları sürece dahil etmenin ve öğrenecekleri şeyler hakkında ortak beklentiler oluşturmanın etkili bir yolu, konuyla ilgili birkaç ön soru sorarak düşünme ve tartışma olanağı yaratmaktır. Etkinlik şu şekilde gerçekleştirilebilir:</p>
<ul>
<li>Katılımcılara algoritmaların günlük yaşamlarındaki yeri hakkında ne düşündükleri sorulabilir</li>
<li>Katılımcılardan, kendilerine verilen örnekleri sınıflandırmaları ve algoritma tarafından alınan kararların/durumların bir listesini yapmaları istenebilir</li>
<li>Katılımcılara, maruz kaldıkları haberlerle algoritmaların bir ilgisi olup olmadığı sorulabilir</li>
<li>Bu algoritmaları kimin yazdığı ve karar parametrelerini kimin belirlediği sorulabilir.</li>
</ul>
<p>Tartışmalardan sonra, algoritmaların günlük hayatımızın her alanında yer aldıkları, başkaları tarafından yazıldıkları ve manipülasyon potansiyeline sahip olduklarının katılımcılar tarafından anlaşıldığından emin olunmalıdır.</p>
<h4 id="dersin-amacinin-belirtilmesi">Dersin Amacının Belirtilmesi</h4>
<p>Amaç netleştirilmelidir. Bu dersin amacı, algoritmalar, günlük yaşamımızdaki yerleri ve manipülasyon potansiyelleri hakkında farkındalık geliştirmektir. Isınma sorularının ardından amaç ve hedefleri netleştirmek daha kolay olacaktır.</p>
<h4 id="ders-iceriginin-sunulmasi">Ders İçeriğinin Sunulması</h4>
<p>İçerik sunulurken katılımcılarla etkileşime girmek ve onları aktif katılıma teşvik etmek şunlar önerilebilir:</p>
<ul>
<li>Algoritmanın tanımı verilmeden önce, katılımcılardan algoritmaların işlevlerini ayrıntılı olarak tanımlamaları istenebilir</li>
<li>Algoritmaların faydalarına ve potansiyel risklerine ilişkin bir genel bakış sunmadan önce, katılımcılardan bunun üzerinde tartışmaları istenebilir.</li>
<li>Arama motorlarında farklı konumlar ve farklı kişiler tarafından aynı konuda yapılan aramalarda farklı sonuçlar elde edileceğinden söz ederken, bu söylem ekran görüntüleriyle veya gerçek zamanlı bir gösteri ile desteklenebilir.</li>
<li>Zaman ve imkanlar izin veriyorsa, katılımcılardan aynı aramayı yapmaları ve sonuçları karşılaştırmaları istenebilir.</li>
<li>Algoritmalar, haberler ve haber akışları arasındaki bağlantı netleştirilmelidir.</li>
<li>Algoritmalara, filtre balonlarına ve yankı odalarına ilişkin kapsamlı bir genel bakış açısı sağlandıktan sonra, katılımcılardan yanlış bilgilerin yayılmasında algoritmaların oynadığı rol hakkında tartışmaları istenebilir.</li>
</ul>
<h4 id="bitirirken">Bitirirken</h4>
<p>Dersin kısa bir özeti yapılırken verilmek istenilen en önemli mesajların tekrarlanmasını sağlayacak birkaç soru sorulabilir.</p>
<ul>
<li>Katılımcılara algoritmaların varlığını bilmenin kontrolü ele almaya faydası olup olmayacağı sorulabilir.</li>
</ul>
<p>Tartışmalardan sonra, katılımcıların algoritmaların bazı durumlarda onların yerine karar verdiğini ve manipülasyon potansiyeli taşıdığını anladıklarından emin olunmalıdır.</p>
</span>
<h2 id="icerik-algoritmalar-cagi">İçerik: Algoritmalar Çağı</h2>
<h3 id="giris">Giriş</h3>
<p>Algoritma, bir sorunu çözmek veya bir görevi yürütmek için bilgisayarlar tarafından bir veri gövdesi üzerinde kullanılan talimatlar ve kurallar dizisidir (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 49). Algoritma, bilgisayarlara belirli bir görevi nasıl tamamlayacaklarını veya verilen verileri nasıl işleyeceklerini söyleyen mini bir kullanım kılavuzu olarak görülebilir (<a href="https://www.thinkautomation.com/eli5/what-is-an-algorithm-an-in-a-nutshell-explanation/" target="_blank">What is an algorithm?, n.d</a>.).</p>
<p>Algoritmalar, bilgileri önceliklendirerek, sınıflandırarak, ilişkilendirerek ve filtreleyerek içeriği düzenler. Önceliklendirme, içeriği bir şeye dikkat çekmek için başka bir şey pahasına sıralar. Sınıflandırma, belirli bir varlığın herhangi bir sayıda özelliğine bakarak belirli bir sınıfın bir bileşeni olarak kategorize edilmesini ifade eder. İlişkilendirme, varlıklar arasındaki ilişkileri belirler. Ve filtreleme, bir dizi kritere dayalı olarak belirli bilgilerin dahil edilmesini veya hariç tutulmasını sağlar (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 4-8).</p>
<p>Filtreleme algoritmaları genellikle önceliklendirme, sınıflandırma ve ilişkilendirme kararlarını hesaba katar. Örneğin haber kişiselleştirme uygulamalarında haberler o haberin nasıl kategorize edildiğine, kişinin ilgi alanları ile nasıl ilişkilendirildiğine ve o kişi için nasıl önceliklendirildiğine göre filtrelenir. Filtreleme kararlarına dayalı olarak bazı bilgiler aşırı vurgulanırken diğerleri sansürlenir (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 4-8).</p>
<p>“Algoritma çağının” yükselişi toplum, siyaset ve haberler üzerinde derin bir etki yaratmıştır. Algoritmalar, inovasyon ve sosyal değişimin güçlü, verimli ve genellikle sorgulanabilir itici güçleridir (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 4). Günümüzde, karar verme görevlerinde insan müdahalesine yardımcı olmak ve bazen tamamen insanların yerini almak için giderek daha karmaşık algoritmalar tasarlanmaktadır. Çünkü algoritmalar çeşitli işlemleri insan çabasından daha düşük bir maliyetle ve daha yüksek verimlilikle yapabilmektedir (<a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, 2016</a>). Otomatik karar vermenin potansiyel faydaları sayısız ve açıktır, ancak aynı zamanda endişeye yol açan bazı riskler de içerirler (<a href="https://doi.org/10.1098/rsta.2017.0364" target="_blank">Olhede &amp; Wolfe, 2019, p. 2</a>).</p>
<p>Algoritmalarla ilgili hızlı gelişmelerin yanı sıra verilerin büyük ölçekli elde edilebilirliği toplumu önemli ölçüde değiştirmiştir (<a href="https://doi.org/10.1098/rsta.2017.0364" target="_blank">Olhede &amp; Wolfe, 2019, p. 2</a>). Günlük hayatta, algoritmalar genellikle insanların ne izledikleri, ne satın aldıkları (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 5) ve hatta nasıl oy kullanacakları (<a href="https://doi.org/10.1073/pnas.1419828112" target="_blank">Epstein &amp; Robertson, 2015</a>) hakkındaki kararları etkilemek için kullanılabilmektedir. Algoritmalar, arama motorlarından arama sonuçlarını filtreler. Kimin bir iş görüşmesine davet edileceğine ve nihayetinde kimin iş teklifi alacağına karar vermek üzere programlanmış olabilirler. Refah ve kamu güvenliği gibi sosyal hizmetleri yönetmek için kullanılabilirler. Hangi kredi başvuru sahiplerinin kredi riskinin daha düşük olduğu konusunda öneride bulunabilirler. Bu görünmez kod satırları tıbbi teşhisler koyabilir ve hatta bir cezanın süresini belirleyebilir (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020,</a> p. 4-5).</p>
<p>Algoritmalar, işletmeleri ve hükümetleri güçlendirebilecek etkili kararlar verir (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 29). Algoritmalar karar verirken, örneğin sağlık hizmetleri, kredi puanlama ve hisse senedi alım-satımında, politik, ekonomik, coğrafi, ırksal veya diğer ayrımcılığı teşvik edebilir (<a href="https://ssrn.com/abstract=1762766" target="_blank">Pasquale, 2011</a>). Algoritmalar, kullanıcıların deneyimlerini ve hatta dünya algılarını şekillendirebilirler (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 3). Faaliyetleri bazen adaletsizliğe yol açabilmesine ve insanların algılarını şekillendirebilmesine ve seçimlerini etkileyebilmesine rağmen, insanlar görünmez olan algoritmaların varlığından genelde habersizdirler.</p>
<p>Bütün bunlar algoritmik gücün zararlı olduğu anlamına gelmez, aynı zamanda olumlu bir güç olarak da kullanılabilirler (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 2). Algoritmalar, aslında, özünde iyi veya kötü değildir. Etkileri, ne yapmak üzere programlandıklarına, programlamayı kimin yaptığına, algoritmaların pratikte nasıl çalıştığına, kullanıcıların onlarla nasıl etkileşime girdiğine ve beslendikleri büyük miktarda kişisel veriyle ne yapıldığına bağlıdır (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 4). Ancak, önyargılarla çalıştırılabildiklerini ve hata yapabileceklerini bilmek önemlidir. Algoritmik kodlar opaktır (şeffaf değildir) ve karmaşık teknik katmanların arkasına gizlenmiştir (<a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, 2013</a>, p. 2).</p>
<p>Algoritmaların etkileri önemlidir (<a href="http://www.realtechsupport.org/UB/ML+CT/papers/selected_papers/Ziewitz_GoverningAlgorithms_2013.pdf" target="_blank">Barocas, Hood &amp; Ziewitz, 2013</a>; <a href="https://dl.acm.org/doi/pdf/10.1145/2559206.2578883" target="_blank">Hamilton, Karahalios, Sandvig &amp; Eslami, 2014</a>; <a href="http://social.cs.uiuc.edu/papers/pdfs/ICA2014-Sandvig.pdf" target="_blank">Sandvig, Hamilton, Karahalios &amp; Langbort, 2014</a>). Örneğin, arama algoritmaları bir toplum için mevcut olan çevrimiçi bilgiyi yapılandırır ve bir bekçi gibi işlev görebilir (<a href="https://www.csd.uoc.gr/~hy474/papers/PoliticsSearchDecadeRetrospective.pdf" target="_blank">Granka, 2010,</a> p. 364-365; <a href="https://www.researchgate.net/publication/2410076_Shaping_The_Web_Why_The_Politics_Of_Search_Engines_Matters" target="_blank">Introna &amp; Nissenbaum, 2000</a>). Bir Web arama motorunun kullanıcılarına sağladığı arama sonuçları, her kullanıcının Web'i görüntüleme biçimi üzerinde çok büyük bir etkiye sahiptir (<a href="https://doi.org/10.1007/978-3-319-04918-2_13" target="_blank">Xing, Meng, Doozan, Feamster, Lee &amp; Snoeren, 2014</a>). Araştırmacılar, kişiselleştirilmiş arama sonuçlarının Google'daki etkisini test etmiş ve sonuçların herhangi bir zamandaki Web içeriği, aramanın yapıldığı bölge, yakın tarihli arama geçmişi ve ne kadar arama motoru manipülasyonu gerçekleştirildiğii gibi çeşitli faktörlere göre farklılık gösterdiğini saptamıştır (<a href="https://doi.org/10.1007/978-3-319-04918-2_13" target="_blank">Xing , Meng, Doozan, Feamster, Lee &amp; Snoeren, 2014</a>).</p>
<center>
<p><img src="../img/module_06/figure_02.jpg"/></p>
<p>Kaynak: <a href="https://www.digifloor.com/google-search-result-shows-different-ui-india-us-30" target="_blank">Gohel, 2013</a></p>
</center>
<p>Araştırmalar, arama motoru şirketleri tarafından sağlanan arama sonuçlarının sıralamasının tüketici tutumları, tercihleri ve davranışları üzerinde çarpıcı bir etkisi olduğunu göstermektedir. İnternet arama sıralamalarının tüketici tercihleri üzerinde önemli bir etkisi vardır, çünkü kullanıcılar daha düşük sıradaki sonuçlara göre daha yüksek sıradaki sonuçlara güvenir ve onları seçerler. Arama sıralamalarının görünen gücü göz önüne alındığında, araştırmacılar, demokratik seçimlerde kararsız seçmenlerin tercihlerini değiştirmek yönünde manipüle edilip edilemeyeceğini araştırmıştır. Bulgular, taraflı arama sıralamalarının kararsız seçmenlerin oy tercihlerini %20 veya daha fazla değiştirebileceğini, kaymanın bazı demografik gruplarda çok daha yüksek olabileceğini ve insanların manipülasyonun farkında olmaması için bu tür sıralamaların maskelenebileceğini göstermiştir (<a href="https://doi.org/10.1073/pnas.1419828112" target="_blank">Epstein &amp; Robertson, 2015</a>).</p>
<p>Matematiksel modeller olarak algoritmalar ve sonuçlarının adil, nesnel ve tarafsız olduğu konusunda yaygın olarak kabul edilen bir yanlış anlama vardır (<a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, 2016</a>). Algoritmalar bilgisayarlar tarafından işlendiğinden ve mantıksal yönergeleri takip ettiğinden, insanlar genellikle onları tarafsız veya değerden bağımsız olarak düşünürler, ancak algoritmalar insanlar tarafından tasarlanmaktadır ve algoritmanın eğitildiği veriler insan önyargılarını taşıyabilmektedir (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 49). Algoritmalar soyut insan davranışlarını değerlendirmede yetersiz kaldıkları gibi gerçekliği ölçmek için kullandıkları veriler de zayıf olabilir. Algoritmalar, nasıl ulaştıklarını açıklamak zorunda kalmadan kararlar alırlar (<a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, 2016</a>). Bunun aksine, insanlar tarafından karar verildiğinde, yargıdaki hataların düzeltilmesine izin veren bir geri bildirim döngüsü vardır (<a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, 2016</a>). Ayrıca, sosyal sitelerin içeriğini tanıtmak için kullandığı algoritmalar, içeriğin geçerliliğini değerlendirmez, bu da yanlış bilgi yayılmasına neden olur (<a href="https://archives.cjr.org/news_literacy/algorithms_filter_bubble.php" target="_blank">Jolly, 2014</a>).</p>
<p>Sonuç olarak algoritmaların kalıcı olduğu ancak dikkatli kullanılması gerektiği söylenebilir (<a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, 2016</a>).</p>
<h3 id="algoritmalar-caginda-yasam-buyuk-resim">Algoritmalar Çağında Yaşam: Büyük Resim</h3>
<p>Bilgi dünyası son on yılda beklenmedik şekillerde değişmiştir. Bu değişiklikler kısmen algoritmaların etkisiyle açıklanabilir. Bu değişiklikleri yönlendiren faktörlerden bazıları <a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister ve MacMillan, (2020</a>, p. 5-7) tarafından aşağıdaki şekilde özetlenen büyük resmi görmemize yardımcı olmaktadır:</p>
<ol>
<li aria-level="4">Günlük hayatımızla ilgili görünmez ve sürekli olarak veri toplanmaktadır.</li>
<li aria-level="4">Veri bilimindeki gelişmeler, sistemlerin verileri gerçek zamanlı, hızlı ve geniş ölçekte (“büyük veri”) toplamasına ve işlemesine olanak tanımaktadır.</li>
<li aria-level="4">Çok sayıda kaynaktan toplanan veriler hızlı bir şekilde ilişkilendirilebilmektedir.</li>
<li aria-level="4">Kimin işe alınacağı, kimin kredi alacağı, sosyal hizmetlere erişim, okula veya eğitim hizmetlerine kabul gibi şeyleri belirleyen sosyal kurum ve süreçlerde artan şekilde otomatik karar verme sistemleri kullanılmaktadır.</li>
<li aria-level="4">Çok önemli kararlar veren makine öğrenimi ve yapay zekaya dayalı sistemler genellikle yanlı veya eksik veri kümelerine dayanmaktadır.</li>
<li aria-level="4">Yayınlanmış bilgilerin ayrıştırılması ve arama ve sosyal medya platformları aracılığıyla yeniden dağıtılması, eskiden farklı olan bu kaynakların (örneğin bilimsel makaleler, gazete hikayeleri) değerlendirilmesini daha zor hale getirmektedir.</li>
<li aria-level="4">Kar amacı güden endüstriler, sonuçları kişiselleştirmek, davranışları tahmin etmek ve yönlendirmek, hedefe yönelik reklamcılık, politik ikna amacıyla insanların bilgisayarlarla etkileşiminden veri toplamaktadır.</li>
<li aria-level="4">Ancak, söz konusu endüstriler, söz konusu veri toplamanın istenmeyen sonuçlarını öngörmekte ve bunlara yanıt vermekte güçlük çekiyor gibi görünmektedir.</li>
<li aria-level="4">Etik kuralları olmayan sosyal medya platformlarının yükselişi, gazetecilik ve bilim gibi yerleşik bilgi geleneklerine güvensizliğin artmasına da sebep olmaktadır.</li>
<li aria-level="4">İnsanların bilgi edinmesini etkileyen, bilgi ve inançlarını şekillendiren teknik altyapı, tasarım gereği büyük ölçüde görünmezdir.</li>
<li aria-level="4">Bilgi sistemleri ve algoritmaların tasarımını kimin elinde tuttuğu ve bu gücün nasıl kullanıldığı konusunda kamuoyunda bilgi eksikliği vardır.</li>
</ol>
<p>Sonuç olarak, algoritmalar çağında bilginin nasıl işlendiğini anlamak bireyler için büyük önem taşımaktadır (<a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 7-8).</p>
<center>
<p><img src="../img/module_06/figure_04.jpg"/></p>
<p>Kaynak: <a href="https://www.projectinfolit.org/uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, Fister &amp; MacMillan, 2020</a>, p. 6.</p>
</center>
<h3 id="haberler-haber-akisi-ve-algoritmalar">Haberler, Haber Akışı ve Algoritmalar</h3>
<p>Diğer şeylerin yanı sıra, dünya ile ilgili gördüğümüz haberleri filtrelemek için de algoritmalar sıklıkla kullanılır. Bugün bireyler sosyal medya, e-posta ve okuma uygulamaları aracılığıyla giderek daha fazla haber keşfediyor, bu nedenle haber sitelerinin ana sayfa trafiği azalmaya devam ediyor. Bu durumun farkında olan ve altyapılarını buna göre ayarlayan yayıncılar ise kullanıcının nereden girdiğine bağlı olarak site deneyimini değiştiren algoritmalar oluşturuyorlar. Sonuç olarak, gazeteler bireyler için özelleştiriliyor ve büyük olasılıkla her birey çevrimiçi gazetelerin ön sayfalarını farklı görüyor. Kullanıcıları ilgilenecekleri içeriğe hızlı ve verimli bir şekilde ulaştırdığından, yayıncılar, çevrimiçi kitlelerin okuma ve paylaşım tercihlerine göre sitelerini optimize etmeyi iyi bir şey olarak görse de bu okuyucular için iyi olmayabilir (<a href="https://archives.cjr.org/news_literacy/algorithms_filter_bubble.php" target="_blank">Jolly, 2014</a>).</p>
<p>Kullanıcılara sık sık güncellenen haberler sunan haber akışları, algoritmaların etkin rol oynadığı bir diğer uygulamadır. Örneğin Facebook Haber Akışı (Facebook News Feed), bir kişinin arkadaş ağı tarafından oluşturulan tüm hikayelerden oluşan bir havuzdan seçilen algoritmik olarak düzenlenmiş veya filtrelenmiş bir hikaye listesi görüntülemektedir (<a href="https://doi.org/10.1145/2702123.2702556" target="_blank">Eslami, Rickman, Vaccaro, Aleyasen, Vuong, Karahalios, Hamilton &amp; Sandvig, 2015</a>, p. 153). Facebook Haber Akışı kürasyon algoritması algılarını incelemek için Facebook kullanıcıları üzerinde yapılan bir araştırma, katılımcıların yarısından fazlasının (%62,5) Haber Akışı kürasyon algoritmasının varlığından hiç haberdar olmadığını ve arkadaşlarından ve takip ettikleri sayfalardan gelen her hikayenin Haber Akışlarında yer aldığını düşündüklerini saptamıştır (<a href="https://doi.org/10.1145/2702123.2702556" target="_blank">Eslami, Rickman, Vaccaro, Aleyasen, Vuong, Karahalios, Hamilton &amp; Sandvig, 2015</a>, p. 153).</p>
<center>
<p><img src="../img/module_06/figure_03.jpg" width="50%"/></p>
<p><a href="https://pixnio.com/media/movie-video-recording-filming-street-television-news" target="_blank">by Bicanski</a></p>
</center>
<p>Algoritmalar, yalnızca insanların ilgilendikleri içeriği bulmasını değil, aynı zamanda algoritmanın onların ilgilendiklerini düşündüğü içeriğin de insanları bulmasını kolaylaştırır. <a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos’a (2013</a>, p. 2) göre bugün algoritmalar, toplumdaki yeni güç simsarlarıdır.</p>
<h3 id="filitre-balonlari">Filitre Balonları</h3>
<p>Filtre Balonu, mevcut bilgi ve görüşlerle çelişen bilgilere maruz kalmaktan kaçınmayı kolaylaştıran kişiselleştirmenin bir sonucu olarak ortaya çıkan entelektüel izolasyondur. Kullanıcıyla ilgili bilgilerin (arama geçmişi, konum ve sosyal medya beslemeleri gibi) küratörlüğünün sonucudur. Sosyal medya platformları, kullandıkları algoritmalar ile kullanıcıları kolaylıkla filtre balonlarına hapsedebilir. Filtre balonları, kullanıcıları, mevcut inanç ve görüşleriyle uyumlu bilgileri yayan, benzer düşünen insanlarla çevrelerken, çelişkili bakış açılarına sahip insanlarla daha az temasa neden olabilir. Google'dan kişiselleştirilmiş arama sonuçları ve Facebook'tan kişiselleştirilmiş haber akışları bu fenomene verilebilecek iki örnektir (<a href="https://www.techopedia.com/definition/28556/filter-bubble" target="_blank">Filter bubble, 2018</a>; <a href="https://literariness.org/wp-content/uploads/2019/06/Literariness.org-Nicole-A.-Cooke-Fake-News-and-Alternative-Facts_-Information-Literacy-in-a-Post-Truth-Era-ALA-Editions-2018.pdf" target="_blank">Cooke, 2018</a>).</p>
<p>Terimi ortaya atan Pariser'e göre, filtre balonu, ön sayfayı oluşturan şeyin önemini belirleyen gazete editörleri gibi "insan bekçilerden", Facebook ve Google tarafından kullanılan ve kullanıcının tıklama olasılığının en yüksek olduğuna inandıkları içeriği getiren algoritmik bekçilere geçişin yarattığı dünyadır (<a href="https://archives.cjr.org/feature/the_king_of_content.php?page=all" target="_blank">Fitts, n.d</a>.). Teknoloji şirketleri ticari kuruluşlardır ve bu nedenle hissedarlarını mutlu etmek için kullanıcıların reklamlara maruz kalma süresini uzatmak amacıyla sitelerinde mümkün olduğunca uzun süre kalmaya teşvik etmeye çalışırlar. Bunu da kullanıcıların geçmişte beğendiği, paylaştığı veya yorumladığı şeylerden yola çıkarak algoritmaları değiştirerek yaparlar (<a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle &amp; Derakhshan, 2017,</a> p.52). Bu yeni dijital evren, "kullanıcının en sevdiği kişiler, nesneler ve fikirlerle dolu rahat bir yer" olarak da tanımlanabilir (<a href="https://archives.cjr.org/feature/the_king_of_content.php?page=all" target="_blank">Fitts, n.d</a>.). Bununla birlikte, bilginin bu seçici teşhiri, yalnızca bilişsel yönleri nedeniyle değil, aynı zamanda ahlaki, politik ve sosyal yönleri nedeniyle de endişeye neden olmaktadır (<a href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research" target="_blank">Cisek &amp; Krakowska, 2018</a>).</p>
<center>
<p><img src="../img/module_06/figure_01.jpg" width="50%"/></p>
<p><a href="https://commons.wikimedia.org/wiki/File:FilterBubble.jpg" target="_blank">Filter bubble by </a><a href="https://commons.wikimedia.org/w/index.php?title=User:Evbestie&amp;action=edit&amp;redlink=1" target="_blank">Evbestie</a> <a href="https://commons.wikimedia.org/wiki/File:FilterBubble.jpg" target="_blank">Lisans CC</a></p>
</center>
<p>Kişiselleştirmenin, ilgili ve faydalı bilgiye erişimi kolaylaştırarak ve geri kalanlardan (alakasız, yararlı olmayan, rahatsız edici vb.) kaçınarak bilgi karmaşası ve aşırı bilgi yüklemesiyle mücadeleye yardımcı olduğu şüphesizdir. Ancak, kendi kendine seçilen kişiselleştirme ile önceden seçilmiş kişiselleştirme arasında önemli bir fark vardır. Önceden seçilmiş kişiselleştirme algoritmalarında kullanıcılar için içerik seçilirken, kendi kendine seçilen kişiselleştirmede insanlar hangi içeriği görmek istediklerine kendileri karar verirler. Açıkçası bu yeni bir şey değildir. İnsanlar her zaman (ve hala) filtre balonlarında yaşadılar çünkü her zaman bilgi bekçileri (ebeveynler, hükümetler, dinler, sosyal gruplar gibi) vardı. Ancak bu balonların görünmez ve istemsiz olduğu durumlarda ciddi endişeler oluşmaktadır. İnsanlar eriştikleri bilgilerin kişiselleştirilmiş olduğunu bilmediklerinde, bunun eksiksiz ve nesnel olduğunu varsayabilirler. Geçit bekçileri olarak algoritmalar (diğer bir deyişle sansür mekanizmaları), içeriğe erişimin yanı sıra başka bakış açıları olduğu konusunda farkındalığını da engelleyebilir. Hepsinden kötüsü, etik ilkelere dayanmıyor olmalarıdır (<a href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research" target="_blank">Cisek &amp; Krakowska, 2018</a>). Filtrelerin değeri inkar edilemez, ancak insanları fikirlere veya olaylara karşı kör bırakma potansiyeli oldukça endişe vericidir (<a href="https://virtualcanuck.ca/2016/10/08/is-google-scholar-a-filter-bubble/" target="_blank">Anderson, 2016</a>).</p>
<p>Filtre balonlarının olumsuz yönleri <a href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research" target="_blank">Cisek ve Krakowska (2018</a>) tarafından şu şekilde özetlenmektedir: Yanıltıcı ve hatalı bir gerçeklik imajı ve bireysel bir zihinsel model yaratma; sınırlı bir bilgi, fikir, dünya görüşü çemberinde kapalı kalma; bilgi edinimini sınırlandırma; doğrulama yanlılığı ve bilişsel önyargı oluşumu; entelektüel ve duygusal tembelliği teşvik etme”.</p>
<p>Filtre balonlarını patlatmak, öncelikle filtre balonlarının var olduğunun farkına varılması ve ardından eleştirel düşünme ve haber okuryazarlığı becerilerinin geliştirilmesi ile mümkündür. <a href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research" target="_blank">Cisek ve Krakowska (2018</a>) filtre balonlarını patlatmak için şu önerilerde bulunmaktadırlar: Algoritmaların seçtikleri şeyleri pasif olarak tüketmek yerine aktif olarak bilgi arama; arama motorları tarafından sunulan gelişmiş arama araçlarını (Boole operatörleri, gelişmiş arama vb.) kullanma; çeşitli arama motorlarını kullanma ve sonuçları karşılaştırma; kullanıcıları takip etmeyen ve kişiselleştirmeyen arama motorlarını kullanmak (DuckDuckGo, Qwant, StartPage gibi); Escape Your Bubble, FleepFeed, Pop Your Bubble gibi filtre balonlarından kurtulmaya yardımcı olan yazılımları kullanma ve ayrıca Deep Web'in varlığını unutmama.</p>
<p><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle ve Derakhshan’a (2017</a>) göre filtre baloncuklarının insanları karşı karşıya bıraktığı en büyük zorluk beyinlerini yeniden alternatif bakış açıları aramak için eğitmektir. Eğer, insanların benzer insanlara bağlı hissetmek veya belirli bir kimliğe bağlı olmak gibi basitçe bilgi sahibi olmanın ötesinde bazı nedenlerden dolayı içerik aradıklarını ve tükettiklerini bilirsek, bu, filtre balonlarını delmenin sadece çeşitli bilgiler sağlamaktan fazlasını gerektirdiği anlamına gelir.</p>
<h3 id="yanki-odalari">Yankı Odaları</h3>
<p>Yankı odası, haber medyasında, inançların kapalı bir sistem içinde tekrarlayan iletişimle güçlendirildiği bir durumun metaforik açıklamasıdır. Bir yankı odasında, insanlar mevcut inançlarını ve görüşlerini güçlendiren bilgilerle karşılaşırlar. Bu, politik ve sosyal kutuplaşmayı ve aşırılığı artırabilecek bilinçsiz bir onaylama yanlılığı uygulaması olarak görülebilir (<a href="https://en.wikipedia.org/wiki/Echo_chamber_(media)" target="_blank">Echo chamber, 2020</a>).</p>
<p>Yankı odaları ve filtre balonları, genellikle birbirinin yerine kullanılan iki yakın kavramdır. Bununla birlikte, yankı odası, bireylerin yalnızca benzer düşünen bireylerden gelen bilgilere maruz kaldığı genel fenomeni ifade ederken, filtre balonları, önceki çevrimiçi davranışlara dayalı olarak içerik seçen algoritmaların bir sonucudur (<a href="https://en.wikipedia.org/wiki/Echo_chamber_(media)" target="_blank">Echo chamber, 2020</a>). Başka bir deyişle, filtre balonları politik ve sosyal sonuçları olabilecek yankı odalarının oluşmasına katkıda bulunur.</p>
<center>
<p><img src="../img/module_06/figure_05.jpg" width="50%"/></p>
<p><a href="https://www.flickr.com/photos/28648431@N00/239657074" target="_blank">"crop circle - echoes"</a>, <a href="https://www.flickr.com/photos/28648431@N00" target="_blank">oddsock</a> Lisans: <a href="https://creativecommons.org/licenses/by/2.0/?ref=ccsearch&amp;atype=rich" target="_blank">CC BY 2.0</a></p>
</center>
<p>Yankı odaları, inançları ve dünya görüşlerini başkalarıyla paylaşmak için, yüzleşme veya bölünme korkusu olmadan güvenli alanlar sağlar (<a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle &amp; Derakhshan, 2017</a>). Dezenformasyon üretenler yankı odaları içindeki grupları hedef alırlar. Çünkü mesaja daha açık olduklarını ve fikirlerine meydan okuyacak kimse olmayacağını bilirler. Mesajın daha sonra ilk alıcılar tarafından paylaşılması da çok muhtemeldir (<a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle &amp; Derakhshan, 2017</a>). Araştırmaların gösterdiği gibi, insanların tanıdıkları birinden gelen bir mesaja güvenme olasılıkları çok daha yüksektir (<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1460-2466.2010.01488.x" target="_blank">Metzger, Flanagin &amp; Medders, 2010</a>). Bu nedenle dezenformasyon çok hızlı bir şekilde yayılabilir. Güvenin yüksek olduğu tanıdıklar (arkadaşlar) arası ağlarda yayılım kolaydır. Temel sorun, filtre balonlarının insanların kendi çevrimiçi yankı odalarında yaşamalarına izin vererek, onları sadece kendi fikirlerini doğrulayan fikirlerle baş başa bırakarak kutuplaşmayı derinleştirmesidir (<a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle &amp; Derakhshan, 2017</a>).</p>
<p>Her iki olgunun da arkasında tekrarlama teorisi yatar ve Central Washington Üniversitesi'ndeki araştırmacıların 2012'de yaptığı bir çalışmada işaret ettiği gibi, sahte haberlerin işe yaramasını sağlayan da budur. Toronto Üniversitesi'nden bir psikolog olan Lynn Hasher, "tekrarlamanın işleri daha makul kıldığını" ve "insanlar diğer bilgilerden yorulduğunda veya dikkati dağıldığında etkinin muhtemelen daha güçlü olduğunu" iddia etmektedir (<a href="https://www.wired.com/2017/02/dont-believe-lies-just-people-repeat/" target="_blank">Dreyfuss, 2017</a>).</p>
<h2 id="alistirmalar">Alıştırmalar</h2>
<script charset="UTF-8" src="https://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js"></script>
<h3 id="alistirma-1">Alıştırma 1</h3>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="370" src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=152" title="EM - TR:  M06 - A1" width="843"></iframe></p>
<h3 id="alistirma-2">Alıştırma 2</h3>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="370" src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=153" title="EM - TR:  M06 - A2" width="843"></iframe></p>
<h2 id="test">Test</h2>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="264" src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=154" title="EM - TR:  M06 - T1" width="843"></iframe></p>
<h2 id="kaynakca">Kaynakça</h2>
<p><a href="https://virtualcanuck.ca/2016/10/08/is-google-scholar-a-filter-bubble/" target="_blank">Anderson, T. (2016)</a>. Is Google Scholar a filter bubble?</p>
<p><a href="http://www.realtechsupport.org/UB/ML+CT/papers/selected_papers/Ziewitz_GoverningAlgorithms_2013.pdf" target="_blank">Barocas, S., Hood, S., &amp; Ziewitz, M. (2013).</a> Governing algorithms: A provocation piece. In Governing Algorithms: A Conference on Computation, Automation, and Control.<a href="http://www.realtechsupport.org/UB/ML+CT/papers/selected_papers/Ziewitz_GoverningAlgorithms_2013.pdf" target="_blank"></a></p>
<p><a href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research" target="_blank">Cisek, S. &amp; Krakowska, M. (2018). </a>The filter bubble: a perspective for information behaviour research. Paper presented at ISIC 2018 Conference.</p>
<p><a href="https://literariness.org/wp-content/uploads/2019/06/Literariness.org-Nicole-A.-Cooke-Fake-News-and-Alternative-Facts_-Information-Literacy-in-a-Post-Truth-Era-ALA-Editions-2018.pdf" target="_blank">Cooke, N. (2018).</a> Fake news and alternative facts: Information literacy in a post-truth era. ALA.</p>
<p><a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, N. (2013).</a> Algorithmic Accountability Reporting: On the Investigation of Black Boxes. Tow Center for Digital Journalism.</p>
<p><a href="https://www.wired.com/2017/02/dont-believe-lies-just-people-repeat/" target="_blank">Dreyfuss, E. (2017).</a> Want to make a lie seem true? Say it again. And again. And again. Wired.<a href="https://www.wired.com/2017/02/dont-believe-lies-just-people-repeat/" target="_blank"></a></p>
<p><a href="https://en.wikipedia.org/wiki/Echo_chamber_(media)" target="_blank">Echo chamber (media). (2020).</a> In Wikipedia.</p>
<p><a href="https://doi.org/10.1073/pnas.1419828112" target="_blank">Epstein, R. &amp; Robertson, R. E. (2015).</a> The search engine manipulation effect (SEME) and its possible impact on the outcomes of elections. In: Proceedings of the National Academy of Sciences 112 (33), E4512-E4521.</p>
<p><a href="https://doi.org/10.1145/2702123.2702556" target="_blank">Eslami, M., Rickman, A.,Vaccaro, K., Aleyasen, A.,Vuong, A., Karahalios, K., Hamilton, K. &amp; Sandvig, C. (2015).</a> "I always assumed that I wasn't really that close to [her]": Reasoning about Invisible Algorithms in News Feeds. In:<a href="https://dl.acm.org/doi/proceedings/10.1145/2702123" target="_blank"> </a>CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (pp. 153–162).</p>
<p><a href="https://www.techopedia.com/definition/28556/filter-bubble" target="_blank">Filter bubble. (2018)</a>. In Technopedia.</p>
<p><a href="https://archives.cjr.org/feature/the_king_of_content.php?page=all" target="_blank">Fitts, A. S. (n.d.). </a>The king of content: How Upworthy aims to alter the Web, and could end up altering the world. Columbia Journalism Review. <a href="https://archives.cjr.org/feature/the_king_of_content.php?page=all" target="_blank"></a></p>
<p><a href="https://www.digifloor.com/google-search-result-shows-different-ui-india-us-30" target="_blank">Gohel, J. (2013).</a> Google shows different UI in India and US.</p>
<p><a href="https://www.csd.uoc.gr/~hy474/papers/PoliticsSearchDecadeRetrospective.pdf" target="_blank">Granka, L. A. (2010).</a> The Politics of Search: A Decade Retrospective. The Information Society, 26(5), 364–374.</p>
<p><a href="https://dl.acm.org/doi/pdf/10.1145/2559206.2578883" target="_blank">Hamilton, K., Karahalios, K., Sandvig, C., &amp; Eslami, M. (2014).</a> A path to understanding the effects of algorithm awareness. In Proc. CHI EA 2014, ACM Press (2014), 631–642. <a href="https://dl.acm.org/doi/pdf/10.1145/2559206.2578883" target="_blank"></a></p>
<p><a href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf" target="_blank">Head, A.J., Fister, B. &amp; MacMillan, M. (2020).</a> Information literacy in the age of algorithms: Student experiences with news and information, and the need for change. Project Information Research Institute.</p>
<p><a href="https://www.researchgate.net/publication/2410076_Shaping_The_Web_Why_The_Politics_Of_Search_Engines_Matters" target="_blank">Introna, L., &amp; Nissenbaum, H. (2000).</a> Shaping the Web: Why the Politics of Search Engines Matters. The Information Society, 16 (3), 169-185.</p>
<p><a href="https://archives.cjr.org/news_literacy/algorithms_filter_bubble.php" target="_blank">Jolly, J. (20 May 2014). </a>How algorithms decide the news you see: Past clicks affect future ones. Columbia Journalism Review.</p>
<p><a href="https://mikekhorev.com/why-do-different-browsers-show-different-search-results-on-google" target="_blank">Khorev, M. (2016).</a> Why do different browsers and devices show different search results on Google?</p>
<p><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1460-2466.2010.01488.x" target="_blank">Metzger, M.J., Flanagin, A.J. &amp; Medders, R.B. (2010)</a> Social and Heuristic Approaches to Credibility Evaluation Online. Journal of Communication, 60(3), 413-439.</p>
<p><a href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf" target="_blank">O’Neil, C. (2016).</a> Weapons of math destruction: How big data increases inequality and threatens democracy. Crown Publishers.</p>
<p><a href="https://doi.org/10.1098/rsta.2017.0364" target="_blank">Olhede, S.C. &amp; Wolfe, P. J. (2019).</a> The growing ubiquity of algorithms in society: Implication, impact and innovation. Philosophical Transactions of the Royal Society, 376 (128).</p>
<p>Pariser, E. (2011). The Filter bubble: How the new personalized Web is changing what we read and how we think. Penguin Books.</p>
<p><a href="https://ssrn.com/abstract=1762766" target="_blank">Pasquale, F. A. (2011).</a> Restoring Transparency to Automated Authority. Journal on Telecommunications and High Technology Law, 9(235).</p>
<p><a href="http://social.cs.uiuc.edu/papers/pdfs/ICA2014-Sandvig.pdf" target="_blank">Sandvig, C., Hamilton, K., Karahalios, K., and Langbort, C. (2014).</a> Auditing algorithms: Research methods for detecting discrimination on internet platforms. In Data Discrimination: Converting Critical Concerns into Productive Inquiry.</p>
<p><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle, C. &amp; Derakhshan (2017).</a> Information disorder: Toward an interdisciplinary framework for research and policymaking. The Council of Europe. <a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank"></a></p>
<p><a href="https://www.thinkautomation.com/eli5/what-is-an-algorithm-an-in-a-nutshell-explanation/" target="_blank">What is an algorithm? An ‘in a nutshell’ explanation. (n.d.)</a>. Think Automation.</p>
<p><a href="https://doi.org/10.1007/978-3-319-04918-2_13" target="_blank">Xing X., Meng W., Doozan D., Feamster N., Lee W. &amp; Snoeren A.C. (2014).</a> Exposing Inconsistent Web Search Results with Bobble. In: Faloutsos M., Kuzmanovic A. (eds) Passive and Active Measurement. PAM 2014. Lecture Notes in Computer Science, vol 8362. Springer, Cham.<a href="https://doi.org/10.1007/978-3-319-04918-2_13" target="_blank"></a></p>
<h2 id="onerilen-kaynaklar">Önerilen Kaynaklar</h2>
<p><a href="https://literariness.org/wp-content/uploads/2019/06/Literariness.org-Nicole-A.-Cooke-Fake-News-and-Alternative-Facts_-Information-Literacy-in-a-Post-Truth-Era-ALA-Editions-2018.pdf" target="_blank">Cooke, N. (2018).</a> Fake news and alternative facts: Information literacy in a post-truth era. ALA.</p>
<p><a href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2" target="_blank">Diakopoulos, N. (2013).</a> Algorithmic Accountability Reporting: On the Investigation of Black Boxes. Tow Center for Digital Journalism.</p>
<h2 id="onerilen-videolar">Önerilen Videolar</h2>
<p><a href="https://www.youtube.com/watch?v=08bD-t-ZyfA&amp;t=88s" target="_blank">Khorev, M. (2017).</a> Why are my search results different than others’ search results?</p>
<p><a href="https://www.youtube.com/watch?v=prx9bxzns3g" target="_blank">Praiser, E. (2018)</a>. How news feed algorithms superchange confirmation bias. Big Think.</p>
<p><a href="https://www.youtube.com/watch?v=pT-k1kDIRnw" target="_blank">GCFLearnFree.org. (2018).</a> How filter bubbles isolate you.</p>
<p><a href="https://www.youtube.com/watch?v=Se20RoB331w" target="_blank">GCFLearnFree.org. (2019).</a> What is an echo chamber?</p>
</div><!--/span-->
</div><!--/row-->
</div><!--/.fluid-container-->
<!-- Le javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="../js/jquery-1.8.3.min.js"></script>
<script src="../js/jquery-ui-1.9.1.custom.min.js"></script>
<script src="../js/bootstrap.bundle.min.js"></script>
<script src="../js/jquery.tocify.js"></script>
<script src="../js/prettify.js"></script>
<script src="../js/user_control.js"></script>
<script>
        $(function() {

            var toc = $("#toc").tocify({
              selectors: "h2,h3,h4,h5"
            }).data("toc-tocify");

            prettyPrint();
            $(".optionName").popover({ trigger: "hover" });

        });
    </script>
</body>
</html>