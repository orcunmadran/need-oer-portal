
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Модул 4: Улога интернета и друштвених мрежа у настанку информационог загађења</title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="This course is designed to help individuals to become smart consumers of news and informed participants in civic life." name="description"/>
<meta content="ESSENTIAL Project Turkish Team" name="author"/>
<!-- Le styles -->
<link href="../css/bootstrap.css" rel="stylesheet"/>
<link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/black-tie/jquery-ui.css" rel="stylesheet"/>
<link href="../css/jquery.tocify.css" rel="stylesheet"/>
<link href="../css/prettify.css" rel="stylesheet" type="text/css">
<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<!-- Le fav icon -->
<link href="../assets/ico/favicon.ico" rel="shortcut icon"/>
<style>
    body {
      padding-top: 20px;
    }
    p {
      font-size: 16px;
    }
    .headerDoc {
      color: #005580;
    }

@media (max-width: 767px) {
    #toc {
        position: relative;
        width: 100%;
        margin: 0px 0px 20px 0px;
    }
}
    </style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VFJPMP12NF"></script>
<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
 		gtag('js', new Date());

 		gtag('config', 'G-VFJPMP12NF');
	</script>
</link></head>
<body>
<div class="container-fluid">
<div class="row-fluid">
<div class="span3">
<div id="toc">
<center>
<br/>
<code class="trainee">За полазнике</code>
<code class="trainer">За тренере</code>
<code class="select"><a href="?userType=trainee">За полазнике</a></code>
<code class="select"><a href="?userType=trainer">За тренере</a></code>
<a href="#top"><img src="../img/index/essential_logo.jpg" width="75%"/></a>
<p><a class="btn btn-secondary btn-small" href="index.html">Почетна страна</a></p>
</center>
</div><!--/.well -->
</div><!--/span-->
<div class="span9">
<div class="hero-unit">
<h1 id="modul-4-uloga-interneta-i-drushtvenikh-mrezha-u-nastanku-informatsionog-zagadjenja">Модул 4: Улога интернета и друштвених мрежа у настанку информационог загађења</h1>
</div>
<h2 id="opis-modula">Опис модула</h2>
<p>Основни циљ овог модула је да објасни улогу интернета и друштвених мрежа у стварању информационог загађења и веродостојности корисника на мрежи.</p>
<p class="trainer">Секундарни циљ је да усмери тренере који желе да користе садржај овог модула за обуку својих полазника.</p>
<p class="trainer">Овим циљевима представљен је утицај интернета и друштвених мрежа на информационо загађење, заједно са смерницама о томе како да се предмет предаје.</p>
<p>Полазници који успешно заврше овај модул моћи ће да:</p>
<ul>
<li>разумеју улогу интернета и друштвених мрежа у стварању информационог загађења</li>
<li>препознају веродостојност корисника на мрежи</li>
<li>препознају неаутентична понашања на мрежи</li>
<li>дефинишу и разликују тролове, ботове и киборге</li>
<li>разумеју мотиве који стоје иза неаутентичних онлајн активности</li>
</ul>
<p class="trainer">Поред тога, тренери који успешно заврше овај модул, моћи ће са већим разумевањем да подучавају о улози интернета и друштвених мрежа у стварању информационог загађења и поузданости корисника на мрежи.</p>
<h2 id="struktura-modula">Структура модула</h2>
<p>Овај модул се састоји из следећих целина:</p>
<ul>
<li>Опис модула (циљеви, опис садржаја и исходи учења)</li>
<li>Структура модула</li>
<li>Смернице за полазнике</li>
<li class="trainer">Смернице за тренере (како се припремити, методе које треба користити и савети за тренере)</li>
<li>Садржај (материјал за учење и вежбање)</li>
<li>Квиз</li>
<li>Референце (цитирани извори, препоручени извори и видео-записи)</li>
</ul>
<p>Главни циљеви модула, опис садржаја и исходи учења објашњени су у делу Опис модула. Смернице за полазнике укључују упутства и сугестије за полазнике. <span class="trainer">Смернице за тренере воде тренере кроз различите фазе обуке и дају савете који би могли да буду корисни током предавања предмета.</span> Садржај обухвата све материјале за учење и вежбања везана за садржај. Квиз укључује питања са вишеструким избором и питања на која се одговара са тачно или нетачнокако би полазници тестирали свој напредак. Одељак Референце обухвата списак извора цитираних у садржају модула и листу додатних извора и видео записа који се препоручују за читање и гледање како би се проширило знање о овој теми.</p>
<h2 id="smernitse-za-polaznike">Смернице за полазнике</h2>
<p>Од полазника се очекује да прочитају текст, пажљиво проуче дате примере, погледају препоручене видео-записе и ураде вежбања. Они могу да консултују предложене ресурсе за додатне информације. Након проучавања садржаја, полазницима се препоручује да ураде квиз како би проценили свој напредак. Уколико је потребно, могу поново проучити материјал за учење.</p>
<h2 class="trainer" id="smernitse-za-trenere">Смернице за тренере</h2>
<p class="trainer">Смернице за тренере укључују сугестије и савете о томе како да користе садржај овог модула за обуку полазника.</p>
<span class="trainer">
<h3 id="priprema">Припрема</h3>
<p>Припремите презентацију (Пауерпоинт/Прези/Канва) која је обогаћена визуелним материјалима (слике и видео клипови) и јасним примерима. Примере и вежбања у овом модулу прилагодите темама којe су познатије конкретној циљној групи. Одабир локалних примера (специфичних за земљу) у вези са актуелним или добро познатим питањима помаже да се поента (суштина) јасније илуструје и додатно привуче пажња полазницима. Што су примери познатији и популарнији, то ће порука бити боље пренета.</p>
<h3 id="pochetak">Почетак</h3>
<p>Како бисте увели полазнике у тему, на почетку можете користити кратак квиз (3 до 5 питања) направљен у Кахуту или им поставити питања путем Ментиметар апликације. Поменути квиз и питалице се могу користити као мотивационо средство и средство за проверу постојећег знања полазника о овој теми. Питања, на пример, могу бити: Шта је трол? Шта је бот?</p>
<h3 id="metodologija">Методологија</h3>
<p>Током обуке могу се комбиновати различите наставне методе:</p>
<ul>
<li>Предавања</li>
<li>Дискусије</li>
<li>Рад у групама</li>
<li>Самопроцењивање</li>
</ul>
<h3 id="saveti-za-trenere">Савети за тренере</h3>
<h4 id="zagrevanje">Загревање</h4>
<p>Ефикасан начин укључивања полазника и утврђивања заједничких очекивања о томе шта ће научити јесте постављање неколико прелиминарних питања о овој теми. Ово се може урадити кроз групни рад, тако што ћете замолити полазнике да дискутују и прикупе идеје, или кроз индивидуални рад, тако што ћете замолити сваког полазника да напише своје идеје на самолепљивим папирићима. Активност се може спровести на следећи начин:</p>
<ul>
<li>Питајте полазнике да ли су икада наишли на неаутентичну активност на друштвеним мрежама. Зашто мисле да је то било неаутентично?</li>
<li>Позовите полазнике да разврстају дате примере и објасне на који начин се разликују.</li>
</ul>
<h4 id="predstavljanje-tsilja-lektsije">Представљање циља лекције</h4>
<p>Циљ лекције треба да буде јасан (објаснити улогу интернета и друштвених мрежа у стварању информационог загађења и поузданости корисника на мрежи). После питања за загревање лакше ћете разјаснити циљеве.</p>
<h4 id="predstavljanje-sadrzhaja-lektsije">Представљање садржаја лекције</h4>
<p>Приликом представљања садржаја водите рачуна о интеракцији са полазницима и подстакните их на активно учешће.</p>
<ul>
<li>Пре него што дате дефиницију тролова, ботова и киборга, замолите учеснике да осмисле своју дефиницију ових појмова.</li>
<li>Приликом представљања уобичајених облика неаутентичних активности и налога, замолите учеснике да дају примере из стварног живота. Продискутујте да ли дати примери припадају или не категорији о којој говорите.</li>
<li>Када дајете примере, изаберите оне из стварног света и сазнајте што више информација о том конкретном случају који износите како бисте полазницима пружили више детаља уколико вас питају.</li>
<li>Како бисте избегли забуну, када бирате примере, уверите се да они у потпуности одговарају дефиницији категорије коју обрађујете.</li>
<li>Створите прилике за практичне вежбе за полазнике кад год је то могуће.</li>
</ul>
<h4 id="zakljuchak">Закључак</h4>
<p>Направите кратак резиме лекције и поставите неколико питања која ће вам помоћи да истакнете најважније поруке које желите да пренесете.</p>
<p>Следеће питање може да вам помогне:</p>
<ul>
<li>Питајте полазнике како би реаговали када посумњају на неаутентичну активност.</li>
</ul>
<p>Када долазите до закључка, побрините се да полазници разумеју да постоје лажни кориснички налози на друштвеним мрежама и скривене намере (најчешће манипулација) иза неаутентичних активности.</p>
</span>
<h2 id="sadrzhaj-uloga-interneta-i-drushtvenikh-mrezha-u-nastanku-informatsionog-zagadjenja">Садржај: Улога интернета и друштвених мрежа у настанку информационог загађења</h2>
<h3 id="uvod">Увод</h3>
<p>Како појава интернета, тако и технологија друштвених мрежа довеле су до фундаменталних промена у начину на који информације настају, саопштавају се и дистрибуирају. Широко доступни, јефтини и софистицирани алати и технологије за уређивање и објављивање олакшали су свакоме креирање садржаја и брзо размењивање информација. Сходно томе, данас су мисинформације  и дезинформације нашле нови канал (<a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle &amp; Derakhshan, 2017</a>, стр. 11-12; <a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf" target="_blank">Tandoc, Lim &amp; Ling, 2018</a>, стр. 139).</p>
<p>Данас се променио не само начин на који се вести дистрибуирају, већ и како оне изгледају. Твит, који има највише 280 карактера, сада се сматра вешћу, а посебно Твитер је постао платформа за брзо ширење ванредних вести. Фејсбук је још једна друштвена мрежа која је постала место где корисници производе, конзумирају и размењују вести, заједно са личним објавама и фотографијама (<a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf" target="_blank">Tandoc, Lim &amp; Ling, 2018</a>, стр. 139).</p>
<p>Све онлајн платформе, посебно друштвене мреже, пружају простор неновинарима да дођу до публике, другим речима, пружају могућности за грађанско новинарство. Неновинари су данас почели да се баве новинарском делатношћу (<a href="https://journals.sagepub.com/doi/full/10.1177/1464884911415973" target="_blank">Robinson &amp; DeShano, 2011</a>, стр. 965). Они преко својих налога на друштвеним мрежама објављују информације, фотографије и видео-записе о најновијим вестима којима су присуствовали (<a href="https://www.academia.edu/40668891/The_trouble_with_twittering_integrating_social_media_into_mainstream_news" target="_blank">Jewitt, 2009</a>, стр. 231).</p>
<p>Друштвени медији обликују медијски пејзаж на неколико начина. Прво, садржај новинских агенција се приказује на једној локацији, па корисници више не морају да бирају извор вести; уместо тога бирају саму причу (<a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406" target="_blank">Messing &amp; Westwood, 2014</a>, стр. 1044). Извор информација је нејасан зато што вести/информације брзо путују од једне до друге особе или канала (<a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf" target="_blank">Tandoc, Lim &amp; Ling, 2018</a>, стр. 139). Друго, одобравање и друштвене препоруке утичу на избор садржаја (<a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406" target="_blank">Messing &amp; Westwood, 2014</a>, стр. 1044). Популарност игра важну улогу у ширењу садржаја. Лајкови, дељења или коментари покрећу додатне лајкове, дељења или коментаре (<a href="https://www.tandfonline.com/doi/full/10.1080/13691180801999027" target="_blank">Thorson, 2008</a>, стр. 475).</p>
<p>Поред тога, за разлику од старих информативних медија, на друштвеним мрежама не постоји етички кодекс због дељења изманипулисаног садржаја (<a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf" target="_blank">Tandoc, Lim &amp; Ling, 2018</a>, стр. 144-145) и постоје потешкоће (које повремено захтевају стручност) у верификацији информација различитих формата као што су фотографије и видео-записи.</p>
<p>Мисинформације и дезинформације су постојале и пре појаве штампе, али је интернет дозволио да се неистине, теорије завера и претеривања шире брже и даље него икад (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<h3 id="verodostojnost-onlajn-korisnika">Веродостојност онлајн корисника</h3>
<p>Веродостојност корисника онлајн заједница је још један проблем (<a href="https://www.sciencedirect.com/science/article/pii/S138912861200179X" target="_blank">Ortega, Troyano, Cruz, Vallejo &amp; Enriquez, 2012</a>, стр. 2884). Сви алати, као и таленат за њихово коришћење, данас су на продају. Свако може да купи хиљаде налога на друштвеним мрежама или милионе имејл адреса, ангажује писце (плаћене објављиваче) који ће допринети да се пропагира било која порука или идеологија у великим размерама (<a href="https://medium.com/the-walkley-magazine/you-cant-sell-news-for-what-it-costs-to-make-7a4def964ffa" target="_blank">Filloux, 2017</a>).</p>
<p>Постоје компаније и појединци који отворено продају Твитер, Фејсбујк и Јутјуб пратиоце, али и интеракције, ретвитове и дељења по разумним ценама (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, November 5, 2018</a>).</p>
<center>
<p><img src="../img/module_04/figure_01.jpg"/></p>
<p>Извор: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a></p>
</center>
<p>Друштвене мреже се све више користе за ширење лажних тврдњи и поларизацију људи око контроверзних питања. Киборзи, тролови и ботови у великој мери доприносе информационом загађењу пунећи интернет дезинформацијама (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<center>
<p><img src="../img/module_04/figure_03.jpg"/></p>
<p>Source: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a></p>
</center>
<h4 id="trolovi-i-farme-trolova-eng-trolls-and-troll-farms">Тролови и фарме тролова (енг. Trolls  аnd Troll Farms)</h4>
<p>Реч трол се односи на људе који намерно иницирају сукобе на мрежи или вређају друге кориснике како би одвукли пажњу и подстакли поделе објављивањем провокативних постова или постова који нису повезани са темом у онлајн заједници или друштвеној мрежи (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a>; <a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf" target="_blank">Wardle, 2018</a>). Циљ је испровоцирати емоционалну реакцију код других и избацити дискусију из колосека, понекад ради сопствене забаве, а понекад као део координисане кампање (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>). Организована група интернет тролова се зове фарма тролова или фабрика тролова.</p>
<p>Тролови су понекад плаћени за ширење информација. Они могу створити значајан (негативан или позитиван) ефекат на онлајн заједнице (<a href="https://www.semanticscholar.org/paper/Battling-the-Internet-water-army%3A-Detection-of-paid-Chen-Wu/26d0d7942e4c0cb24abef3abea6d763d4da668f5" target="_blank">Chen, Wu, Srinivasan &amp; Zhang, 2013</a>). Пропаганда креирана на овај начин често је заснована на чињеницама, али укључује пристрасност која промовише одређени производ, страну или перспективу. Циљ таквог мешања вести и мишљења је често убеђивање, а не информисање (<a href="https://edisciplinas.usp.br/pluginfile.php/4948550/mod_resource/content/1/Fake%20News%20Digital%20Journalism%20-%20Tandoc.pdf" target="_blank">Tandoc, Lim &amp; Ling, 2018</a>, стр. 147).</p>
<p>На пример, <i>Internet Water Army</i> из Кине је група плаћена да објављује онлајн коментаре са одређеним садржајем на интернету. Компаније регрутују ове људе да би промовисали позитивне вести о својим производима и негативне вести о својим конкурентима на појединим онлајн платформама (<a href="https://en.wikipedia.org/wiki/Internet_Water_Army" target="_blank">Internet Water Army, 2020</a>). С друге стране, <i>50 Cent Party/Army</i>, је група коментатора које кинеске власти ангажују да манипулишу јавним мњењем у корист Комунистичке партије Кине. Резултати истраживања са Харварда процењују да кинеска влада измисли око 448 милиона постова на друштвеним мрежама сваке године (<a href="https://gking.harvard.edu/files/gking/files/how_the_chinese_government_fabricates_social_media_posts_for_strategic_distraction_not_engaged_argument.pdf" target="_blank">King, Pan &amp; Roberts, 2017</a>; <a href="https://en.wikipedia.org/wiki/50_Cent_Party" target="_blank">50 Cent Party, 2020</a>).</p>
<center>
<p><img src="../img/module_04/figure_02.jpg"/></p>
<p>Извор: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a></p>
</center>
<p>У последње време, коришћење интернет тролова за манипулацију мишљењем је постала уобичајена пракса. Популаран начин троловања је прављење контроверзних постова са лажних профила на одређену тему који имају за циљ да победе у расправи по сваку цену, а обично су праћени нетачним и обмањујућим информацијама (<a href="https://www.aclweb.org/anthology/R15-1058.pdf" target="_blank">Mihaylov, Koychev, Georgiev &amp; Nakov, 2015, стр. 443</a>).</p>
<div class="well">
<h5 id="primer-bil-gejts-na-meti-trolova">Пример: Бил Гејтс на мети тролова</h5>
<p>Напади на Била Гејтса  путем друштвених мрежа су се интензивирали у априлу 2020. године, након што је на Инстаграму објавио видео како на прозор поставља натпис “Хвала вам здравствени радници.” Током наредних дана, објава је засута стотинама хиљада коментара који су га повезивали са различитим теоријама завере које укључују вакцине, Светску здравствену организацију (СЗО) и имплантирње микрочипова. Напади су ескалирали следеће недеље након што је он критиковао одлуку Трампове администрације да обустави финансирање СЗО. У 24 сата након коментара Била Гејтса, његов налог на Твитеру је поменут најмање 270.000 пута — више од 30 пута више од просека — углавном од стране љутих присталица председника Трампа (<a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank">Stronder, 21. мај 2020</a>).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="../img/module_04/figure_05.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_04.jpg"/><br/><br/><img src="../img/module_04/figure_07.jpg"/></center></td>
</tr>
<tr>
<td><center><p>Извор: <a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank">Schlosser, 15. април 2020.</a></p></center></td>
<td><center><p>Извор: <a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank">Seetharaman, 17. април 2020.</a></p></center></td>
</tr>
</table></center>
</div>
<div class="well">
<h5 id="primer-pokushaj-trolova-da-podstaknu-podele-medju-kanadjanima-uochi-izbora-2017-godine">Пример: Покушај тролова да подстакну поделе међу Канађанима уочи избора 2017. године</h5>
<p>Резултати истраживања, спроведеног на 18.533 твита који су објављени од јануара до фебруара 2017. године, показују да су тролови покушавали да подстакну поделе међу Канађанима уочи избора 2017. године, твитовањем лажних вести и исламофобичних изјава након пуцњаве у џамији у Квебеку 2017. (<a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank">Al-Rawi &amp; Jiwani, 23. јул 2019</a>).</p>
<center>
<p><img src="../img/module_04/figure_06.jpg"/></p>
<p>Извор: <a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank">Al-Rawi &amp; Jiwani, 23. јул 2019</a></p>
</center>
</div>
<p>Трол се разликује од бота по томе што је трол прави корисник, док су ботови аутоматизовани. Троловање као активност није ограничено само на тролове. Тролови понекад користе ботове да би појачали неке од својих порука, па се тако ботови могу користити у сврхе троловања (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар, 2018</a>).</p>
<h4 id="nalog-sa-alternativnim-onlajn-identitom-eng-sock-puppet-account">Налог са алтернативним онлајн идентитом (енг. Sock Puppet Account)</h4>
<p>Налог са алтернативним онлајн идентитом је врста лажног налога. Док појединци користе анонимне налоге само да би избегли да се идентификују, други власници овакве врсте налога их користе да нападају своје критичаре или да се хвале (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<div class="well">
<h5 id="primer-nalog-sa-alternativnim-onlajn-identitom-americhkog-senatora">Пример: Налог са алтернативним онлајн идентитом америчког сенатора</h5>
<p>Мит Ромни, амерички сенатор из Јуте, признао је да води има тајни налог на Твитеру под именом “Pierre Delecto,” који је користио да би се бранио од критика (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="../img/module_04/figure_09.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_08.jpg"/></center></td>
</tr>
</table></center>
<center><p>Source: <a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank">Feinberg, 20. октобар 2019 </a></p></center>
</div>
<h4 id="botovi-i-mrezhe-botova-eng-bots-and-botnets">Ботови и мрежe ботова (енг. Bots And Botnets)</h4>
<p>Бот је аутоматизовани налог на друштвеним мрежама којим управља алгоритам, а не стварна особа. Другим речима, бот је дизајниран да објављује постове без људске асистенције. Три кључна индикатора бота су анонимност, висок ниво активности и потенцирање одређених корисника, тема или хештегова (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a>). Док аутентични корисници Твитера често објављују постове неколико пута дневно о различитим темама, ботови ће твитовати стотине пута дневно и то често само на одређену тему. Већа је вероватноћа да ће репостовати (поново објавити) садржај него да ће креирати нешто оригинално (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>). Ботови могу да користе хештегове и објављују садржај који напослетку може утицати на алгоритам различитих платформи друштвених мрежа (<a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank">Stronder, 21. мај 2020</a>).</p>
<p>Уколико налог објављује појединачне постове и коментарише, одговара или на други начин ступа у интеракцију са објавама других корисника, онда се тај  налог не може класификовати као бот. Ботови се углавном налазе на Твитеру и другим друштвеним мрежама које дозвољавају корисницима да креирају више налога (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a>).</p>
<p>У кампањама дезинформисања, ботови се могу користити да скрену пажњу на обмањујуће наративе, да платформама отму листе трендова и да створе илузију јавне расправе и подршке (<a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf" target="_blank">Wardle, 2018</a>). Студија коју су спровели истраживачи са Универзитета Јужна Калифорнија анализирала је твитове везане за америчке изборе објављене током септембра и октобра 2016. године и открила да је сваки пети твит послао бот (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<div class="well">
<h5 id="primer-tokom-izbijanja-pandemije-oko-45-tvitova-su-poslali-botovi">Пример: Током избијања пандемије око 45% твитова су послали ботови</h5>
<p>Према истраживачима са Универзитета Карнеги Мелон, скоро половина Твитер налога који на друштвеним мрежама шире поруке о пандемији коронавируса вероватно су ботови. Истраживачи су прегледали више од 200 милиона твитова који су на почетку избијања пандемије спомињали вирус, и открили да је око 45% послато са налога који се више понашају као ботови. Истраживачи су идентификовали више од 100 врста нетачних прича о ковид-19 вирусу, попут оних о потенцијалним излечењима. Ботови су такође доминирали разговорима о укидању наредби о останку код куће и “поновном отварању Америке“ (<a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank">Young, May 27, 2020</a>).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="../img/module_04/figure_12.jpg"/></center></td>
<td><center><img src="../img/module_04/figure_10.jpg"/></center></td>
</tr>
<tr>
<td><center><p>Извор: <a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank">Young, 27. мај 2020/</a></p></center></td>
<td><center><p>Source: <a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank">SBenson, 24. април 2020</a></p></center></td>
</tr>
</table></center>
</div>
<p>Мрежа ботова је мрежа бот налога којима управља исти појединац или група. Особе (појединци) који управљају мрежама ботова, које захтевају оригинални људски допринос пре распоређивања, називају се бот фармери или пастири. Циљ мрежe ботова је да учини као да се о хештегу, кориснику или кључној речи прича више (позитивно или негативно) или да је популарнији него што заиста јесте. Ботови циљају алгоритме друштвених мрежа како би утицали на одељак објава у тренду, што резултира изагању несуђених корисника разговорима које појачавају ботови. Мрежe ботова ретко циљају праве кориснике, а када то раде, то је да би их спамовали или генерално узнемиравали, а не да би активно покушавали да промене њихово мишљење или политичке ставове (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a>).</p>
<div class="well">
<h5 id="primer-uochi-izbora-u-maleziji-otkrivene-su-aktivnosti-bota">Пример: Уочи избора у Малезији откривене су активности бота</h5>
<p>Уочи избора у Малезији, DFRLab је пронашао 22.000 ботова и сви они су користили потпуно исти образац говора. Сваки бот је користио два хeштега који су циљали опозициону коалицију и такође је означавао (таговао) између 13 и 16 стварних корисника како би их подстакао да се укључе у разговор (<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018</a>).</p>
<center>
<img src="../img/module_04/figure_11.jpg"/>
<p>Извор: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, 5. новембар 2018.</a></p>
</center>
</div>
<h4 id="kiborzi-eng-cyborgs">Киборзи (енг. Cyborgs)</h4>
<p>Киборг је врста хибридног налога који обједињује неуморност бота и људску суптилност. Киборг налози су они где човек повремено преузима налог бота да би одговорио другим корисницима и поставио оригинални садржај. Они су скупљи и захтевају више времена за рад, али их је много теже ухватити и открити (<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, 7. фебруар 2020</a>).</p>
<h2 id="vezhbanje">Вежбање</h2>
<p>Трол је прави корисник, док је бот аутоматизован. Ботом управља алгоритам, а не стварна особа. Бот је дизајниран да објављује постове без људске асистенције, док је киборг нека врста хибридног налога који комбинује бота и стварну особу.</p>
<h2 id="kviz">Квиз</h2>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="301" src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=53" title="Essential MOOC - SR: Part 1 - Module 4 - Quiz 1" width="958"></iframe><script charset="UTF-8" src="https://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js"></script></p>
<h2 id="referentse">Референце</h2>
<p><a href="https://en.wikipedia.org/wiki/50_Cent_Party" target="_blank">50 Cent Party. (2020).</a> In Wikipedia.</p>
<p><a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank">Al-Rawi, A. &amp; Jiwani, J. (July 23, 2019).</a> Russian Twitter trolls stoke anti-immigrant lies ahead of Canadian election. The Conversation.<a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank"></a></p>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank"></a></p>
<p><a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank">Benson, T. (April, 24, 2020).</a> Trolls and bots are flooding social media with disinformation encouraging states to end quarantine. Insider.<a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank"></a></p>
<p><a href="https://www.semanticscholar.org/paper/Battling-the-Internet-water-army%3A-Detection-of-paid-Chen-Wu/26d0d7942e4c0cb24abef3abea6d763d4da668f5" target="_blank">Chen, C., Wu, K., Venkatesh, S. &amp; Zhang, X. (2013).</a> Battling the Internet Water Army: Detection of hidden paid posters. Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. Niagara, Canada: ACM.</p>
<p><a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank">Feinberg, A. (October 20, 2019).</a> This sure looks like Mitt Romney’s secret Twitter account (Update: It is): Meet “Pierre Delecto”. The Slate.<a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank"> https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html</a></p>
<p><a href="https://medium.com/the-walkley-magazine/you-cant-sell-news-for-what-it-costs-to-make-7a4def964ffa" target="_blank">Filloux, F. (2017).</a> You can’t sell news for what it costs to make. The Walkley Magazine on Medium.</p>
<p><a href="https://en.wikipedia.org/wiki/Internet_Water_Army" target="_blank">Internet Water Army. (2020).</a> In Wikipedia.</p>
<p><a href="https://www.academia.edu/40668891/The_trouble_with_twittering_integrating_social_media_into_mainstream_news" target="_blank">Jewitt, R. (2009).</a> The trouble with twittering: Integrating social media into mainstream news. International Journal of Media &amp; Cultural Politics, 5(3), 233–246. doi:10.1386/- macp.5.3.233_3</p>
<p><a href="https://gking.harvard.edu/files/gking/files/how_the_chinese_government_fabricates_social_media_posts_for_strategic_distraction_not_engaged_argument.pdf" target="_blank">King, G., Pan, J. &amp; Roberts, M. E. (2017).</a> How the Chinese government fabricates Social Media posts for strategic distraction, not engaged argument. American Political Science Review, 111(3), 484-501. DOI:<a href="http://dx.doi.org/10.1017/S0003055417000144" target="_blank"> 10.1017/S0003055417000144 </a></p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, D. (February 7, 2020).</a> Cyborgs, trolls and bots: A guide to online misinformation.<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank"></a></p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406" target="_blank">Messing, S., &amp; Westwood, S. J. (2014).</a> Selective exposure in the age of social media: Endorsements trump partisan source affiliation when selecting news online. Communication Research, 41(8), 1042-1063.</p>
<p><a href="https://www.aclweb.org/anthology/R15-1058.pdf" target="_blank">Mihaylov, T., Koychev, I., Georgiev, G.D. &amp; Nakov, P. (2015).</a> Exposing paid opinion manipulation trolls. In: Proceedings of Recent Advances in Natural Language Processing (стр. 443–450), Hissar, Bulgaria, Sep 7–9 2015.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S138912861200179X" target="_blank">Ortega, F. J., Troyano, J., Cruz, F., Vallejo, C. &amp; Enriquez, F. (2012).</a> Propagation of trust and distrust for the detection of trolls in a social network. Computer Networks. 56. 2884-2895. 10.1016/j.comnet.2012.05.002.</p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1464884911415973" target="_blank">Robinson, S., &amp; DeShano, C. (2011).</a> ‘Anyone can know’: Citizen journalism and the interpretive community of the mainstream press. Journalism, 12(8), 963–982. doi:10.1177/1464884911415973.</p>
<p><a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank">Seetharaman, D. (April 17, 2020).</a> Bill Gates is targeted by Social-Media mobs. The Wall Street Journal.<a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank"></a></p>
<p><a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank">Schlosser, K. (April 15, 2020).</a> Bill Gates calls Trump’s freeze on WHO funding ‘dangerous’ and tweet draws a viral response. GeekWire.<a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank"></a></p>
<p><a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank">Stronder (May 21, 2020).</a> Fighting disinformation, trolls, and bots on social media during COVID-19.<a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank"></a></p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143" target="_blank">Tandoc, E.C., Lim, Z. W. &amp; Ling, R. (2018).</a> Defining “fake news”. Digital Journalism, 6(2), 137-153. DOI: 10.1080/21670811.2017.1360143</p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/13691180801999027" target="_blank">Thorson, E. (2008).</a> Changing patterns of news consumption and participation. Information, Communication and Society, 11(4), 473–489. doi:10.1080/13691180801999027.</p>
<p><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle, C. &amp; Derakhshan, H. (2017).</a> Information disorder: Toward an interdisciplinary framework for research and policymaking. The Council of Europe.</p>
<p><a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf" target="_blank">Wardle, C. (2018).</a> The Essential Glossary.</p>
<p><a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank">Young, V. A. (May 27, 2020)</a>. Nearly half of the Twitter accounts discussing 'reopening America' may be bots. Carnegie Mellon University News.<a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank"></a></p>
<p><a href="https://www.ft.com/content/b4f27934-944a-11e8-b67b-b8205561c3fe" target="_blank">Yang, Y. (August 1, 2018). </a>China’s battle with the internet water army.</p>
<h2 id="preporucheni-izvori">Препоручени извори</h2>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank"> https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/</a></p>
<p><a href="https://medium.com/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c" target="_blank">DFR Lab. (August 29, 2017).</a> #BotSpot: Twelve Ways to Spot a Bot: Some tricks to identify fake Twitter accounts.<a href="https://medium.com/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c" target="_blank"></a></p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, D. (February 7, 2020). </a>Cyborgs, trolls and bots: A guide to online misinformation.<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank"></a></p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" target="_blank">Wild, J. &amp; Godart, C. (2020).</a> Spotting bots, cyborgs and inauthentic activity. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" target="_blank">Zadrozny, B. (2020).</a> Investigating social media accounts. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<h2 id="preporucheni-video-zapisi">Препоручени видео-записи</h2>
<p><a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" target="_blank">Associated Press. (2020).</a> Cyborgs, trolls and bots: AP explains online misinformation<a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" target="_blank"> </a></p>
</div><!--/span-->
</div><!--/row-->
</div><!--/.fluid-container-->
<!-- Le javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="../js/jquery-1.8.3.min.js"></script>
<script src="../js/jquery-ui-1.9.1.custom.min.js"></script>
<script src="../js/bootstrap.bundle.min.js"></script>
<script src="../js/jquery.tocify.js"></script>
<script src="../js/prettify.js"></script>
<script src="../js/user_control.js"></script>
<script>
        $(function() {

            var toc = $("#toc").tocify({
              selectors: "h2,h3,h4,h5"
            }).data("toc-tocify");

            prettyPrint();
            $(".optionName").popover({ trigger: "hover" });

        });
    </script>
</body>
</html>
