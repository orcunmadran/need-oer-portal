
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<title>MODUL 4: VLOGA INTERNETA in DRUŽBENIH MEDIJEV pri USTVARJANJU INFORMACIJSKE ONESNAŽENOSTI</title>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="This course is designed to help individuals to become smart consumers of news and informed participants in civic life." name="description"/>
<meta content="ESSENTIAL Project Turkish Team" name="author"/>
<!-- Le styles -->
<link href="css/bootstrap.css" rel="stylesheet"/>
<link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/black-tie/jquery-ui.css" rel="stylesheet"/>
<link href="css/jquery.tocify.css" rel="stylesheet"/>
<link href="css/prettify.css" rel="stylesheet" type="text/css">
<!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
<!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<!-- Le fav icon -->
<link href="../assets/ico/favicon.ico" rel="shortcut icon"/>
<style>
    body {
      padding-top: 20px;
    }
    p {
      font-size: 16px;
    }
    .headerDoc {
      color: #005580;
    }

@media (max-width: 767px) {
    #toc {
        position: relative;
        width: 100%;
        margin: 0px 0px 20px 0px;
    }
}
    </style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-VFJPMP12NF"></script>
<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
 		gtag('js', new Date());

 		gtag('config', 'G-VFJPMP12NF');
	</script>
</link></head>
<body>
<div class="container-fluid">
<div class="row-fluid">
<div class="span3">
<div id="toc">
<center>
<br/>
<code class="trainee">Za udeležence</code>
<code class="trainer">Za izvajalce</code>
<code class="select"><a href="?userType=trainee">Trainees Edition</a></code>
<code class="select"><a href="?userType=trainer">Trainers Edition</a></code>
<a href="#top"><img src="img/index/essential_logo.jpg" width="75%"/></a>
<p><a class="btn btn-secondary btn-small" href="index.html">VSI MODULI</a></p>
</center>
</div><!--/.well -->
</div><!--/span-->
<div class="span9">
<div class="hero-unit">
<h1 id="modul-4-vloga-interneta-in-druzbenih-medijev-pri-ustvarjanju-informacijske-onesnazenosti">MODUL 4: VLOGA INTERNETA in DRUŽBENIH MEDIJEV pri USTVARJANJU INFORMACIJSKE ONESNAŽENOSTI</h1>
</div>
<h2 id="opis-modula">Opis modula</h2>
<p>Glavni namen tega modula je razložiti vlogo interneta in družbenih medijev pri ustvarjanju informacijske onesnaženosti in verodostojnosti spletnih uporabnikov.</p>
<p>Sekundarni namen je usmerjati izvajalce usposabljanja, ki želijo vsebino tega modula uporabiti pri usposabljanju svojih udeležencev.</p>
<p>S temi cilji je predstavljen vpliv interneta in družbenih medijev na informacijsko onesnaževanje skupaj s smernicami, kako poučevati to temo.</p>
<p>Udeleženci, ki bodo uspešno zaključili ta modul, bodo znali:</p>
<ul>
<li>razumeti vlogo interneta in družbenih medijev pri ustvarjanju informacijskega onesnaževanja</li>
<li>prepoznati verodostojnost spletnih uporabnikov</li>
<li>prepoznati neavtentično spletno vedenje</li>
<li>opredeliti in razlikovati med troli, boti in kiborgi</li>
<li>razumeti motivacijo za neavtentične spletne dejavnosti  </li>
</ul>
<p>Poleg tega bodo izvajalci usposabljanja, ki bodo uspešno zaključili ta modul, lahko pokazali, da razumejo, kako poučevati vlogo interneta in družbenih medijev pri ustvarjanju informacijske onesnaženosti in zaupanja vrednih spletnih uporabnikov.</p>
<h2 id="struktura-modula">Struktura modula</h2>
<p>Ta modul je sestavljen iz naslednjih delov:</p>
<ul>
<li>Cilj, opis vsebine in učni rezultati</li>
<li>Struktura modula</li>
<li>Smernice za udeležence</li>
<li>Smernice za izvajalce usposabljanja (kako se pripraviti, metode, nasveti za izvajalce usposabljanja)</li>
<li>Vsebina (gradivo in vaje)</li>
<li>Kviz</li>
<li>Viri (reference in priporočeni viri ter videoposnetki)</li>
</ul>
<p>Glavni cilji modula, opis vsebine in učni rezultati so pojasnjeni v delu Opis modula. Smernice za udeležence usposabljanja vključujejo navodila in predloge za udeležence izobraževanja. Smernice za izvajalce usposabljanja vodijo izvajalce usposabljanja skozi različne faze usposabljanja in vsebujejo nasvete, ki bi lahko bili koristni pri poučevanju predmeta. Vsebina vključuje vsa študijska gradiva in vaje, povezane z vsebino. Kviz vključuje vprašanja z več možnostmi izbire in resnična/nepravilna vprašanja, s katerimi lahko udeleženci usposabljanja preverijo svoj napredek. Viri vsebujejo dve komponenti: reference in priporočene vire za nadaljnje branje in študij. Reference so seznam virov, navedenih v vsebinskem delu. Priporočeni viri so sestavljeni iz seznama dodatnih virov in videoposnetkov, ki jih priporočamo za branje in gledanje, da bi se naučili več o temi.</p>
<h2 id="smernice-za-udelezence">Smernice za udeležence</h2>
<p>Udeleženci morajo prebrati besedilo, si ogledati priporočene videoposnetke in izvesti vaje. Za dodatne informacije lahko poiščejo predlagane vire. Udeležencem se priporoča, da po končanem študiju vsebine opravijo kviz, s katerim bodo ocenili svoj napredek. Po potrebi lahko ponovno pregledajo študijsko gradivo.</p>
<h2 id="smernice-za-izvajalce-usposabljanja">Smernice za izvajalce usposabljanja</h2>
<span class="trainer">
<p style="font-weight: 400;">Smernice za izobraževalce vključujejo predloge in nasvete o tem, kako predstaviti vsebino tega modula odraslim.</p>
<h3 id="priprava" style="font-weight: 400;">Priprava</h3>
<p style="font-weight: 400;">Priporočamo pripravo predstavitve (PowerPoint/Prezi/Canva), obogatene z vizualnim gradivom (slike in videoposnetki) in jasnimi primeri. Predlagamo tudi, da primere in vaje iz tega modula prilagodite vprašanjem, ki so bolj znana dejanski ciljni skupini. Izbira lokalnih primerov (specifičnih za posamezno državo) v zvezi z aktualnimi ali dobro znanimi vprašanji pomaga jasneje ponazoriti določeno točko. Prav tako pomaga pritegniti pozornost udeležencev usposabljanja. Bolj kot so primeri znani in priljubljeni, bolje bo sporočilo posredovano.</p>
<h3 id="kako-zaceti" style="font-weight: 400;">Kako začeti</h3>
<p style="font-weight: 400;">Na začetku lahko uporabite kratek kviz (3 do 5 vprašanj) v programu Kahoot ali vprašanja z Mentimetrom, da udeležence pritegnete k temi. Uporablja se lahko kot motivacijsko orodje in tudi kot orodje za preverjanje obstoječega znanja udeležencev o temi. Nekateri primeri vprašanj so lahko naslednji: Kaj je trol? Kaj je bot?</p>
<h3 id="ucne-metode" style="font-weight: 400;">Učne metode</h3>
<p style="font-weight: 400;">Med usposabljanjem se lahko kombinirajo različne učne metode. Na primer:</p>
<ul>
<li style="font-weight: 400;">predavanje</li>
<li style="font-weight: 400;">diskusija</li>
<li style="font-weight: 400;">delo v skupinah</li>
<li style="font-weight: 400;">samorefleksija</li>
</ul>
<h3 id="nasveti-za-izobrazevalca" style="font-weight: 400;">Nasveti za izobraževalca</h3>
<h4 id="ogrevanje" style="font-weight: 400;">Ogrevanje</h4>
<p style="font-weight: 400;">Učinkovit način vključevanja udeležencev in določanja skupnih pričakovanj o tem, kaj se bodo naučili, je postaviti nekaj predhodnih vprašanj o temi. To lahko storite s skupinskim delom, tako da udeležence usposabljanja pozovete k razpravi in zbiranju idej, lahko pa tudi individualno, tako da vsakega udeleženca prosite, naj svoje ideje zapiše na samolepilne lističe. Dejavnost se lahko izvede na naslednji način:</p>
<ul>
<li style="font-weight: 400;">Udeležence vprašajte, ali so kdaj naleteli na neavtentično dejavnost v družabnih medijih. Zakaj menijo, da je bila neavtentična?</li>
<li style="font-weight: 400;">Povabite udeležence usposabljanja, da dane primere razvrstijo v kategorije in razložijo, v čem se razlikujejo.</li>
</ul>
<p style="font-weight: 400;"></p>
              Predstavitev učnih ciljev
              <p style="font-weight: 400;">Jasno je treba opredeliti cilj (to je pojasniti vlogo interneta in družbenih medijev pri ustvarjanju informacijske onesnaženosti in zaupanja vrednih spletnih uporabnikov). Po ogrevalnih vprašanjih bo lažje pojasniti cilje.</p>
<h4 id="predstavitev-ucnih-vsebin" style="font-weight: 400;">Predstavitev učnih vsebin</h4>
<p style="font-weight: 400;">Med predstavljanjem vsebine poskrbite za interakcijo z udeleženci in jih spodbudite k aktivnemu sodelovanju.</p>
<ul>
<li style="font-weight: 400;">Preden podate opredelitev trolov, botov in kiborgov, prosite udeležence, naj sami oblikujejo svojo.</li>
<li style="font-weight: 400;">Pri predstavitvi običajnih oblik neavtentičnih dejavnosti in računov udeležence prosite, naj navedejo primere iz resničnega življenja. Primere komentirajte ne glede na to, ali spadajo v kategorijo, o kateri govorite, ali ne.</li>
<li style="font-weight: 400;">Pri navajanju primerov izberite primere iz resničnega sveta in pridobite čim več informacij o tem konkretnem primeru. Tako boste lahko na vprašanja udeležencev odgovorili z več podrobnostmi.</li>
<li style="font-weight: 400;">Ko izbirate primere, se v izogib zmedi prepričajte, da stoodstotno ustrezajo opredelitvi kategorije, ki jo obravnavate.</li>
<li style="font-weight: 400;">Ustvarite priložnosti za praktično vadbo za udeležence usposabljanja, kadar koli je to mogoče.</li>
</ul>
<p style="font-weight: 400;"></p>
<h4 id="zakljucek" style="font-weight: 400;">Zaključek</h4>
<p style="font-weight: 400;">Naredite kratek povzetek učne ure in postavite nekaj vprašanj, ki bodo pomagala razbrati najpomembnejša sporočila, ki jih želite posredovati.</p>
<p style="font-weight: 400;"></p>
<p style="font-weight: 400;">Pri tem so vam lahko v pomoč naslednja vprašanja:</p>
<ul>
<li style="font-weight: 400;">Vprašajte udeležence usposabljanja, kako bi se odzvali, če bi posumili na neavtentično dejavnost.</li>
</ul>
<p style="font-weight: 400;">Ob zaključku se prepričajte, da udeleženci razumejo, da v družbenih medijih obstajajo lažni uporabniški računi in da se za neavtentičnimi dejavnostmi skrivajo nameni (predvsem manipulacija).</p>
</span>
<h2 id="vsebina-vloga-interneta-in-druzbenih-medijev-pri-ustvarjanju-informacijske-onesnazenosti">Vsebina: Vloga interneta in družbenih medijev pri ustvarjanju informacijske onesnaženosti</h2>
<h3 id="uvod">Uvod</h3>
<p>Pojav interneta in tehnologij družbenih medijev je povzročil temeljne spremembe v načinu pridobivanja, sporočanja in razširjanja informacij. Široko dostopna, poceni in izpopolnjena orodja za urejanje in objavljanje ter tehnologija so vsakomur olajšali ustvarjanje vsebin in hitro izmenjavo informacij. Posledično so danes napačne informacije/dezinformacije našle nov kanal (Wardle in Derakhshan, 2017, str. 11-12; Tandoc, Lim in Ling, 2018, str. 139).</p>
<p>Danes se ni spremenilo le to, kako se novice razširjajo, temveč tudi to, kako so videti. Tvit, dolg največ 280 znakov, zdaj velja za novico, Twitter pa je postal platforma zlasti za hitro razširjanje svežih novic. Facebook je še ena platforma družbenih medijev, ki je postala prostor, kjer uporabniki ustvarjajo, berejo in izmenjujejo novice skupaj z informacijami in fotografijami iz zasebnega življenja (Tandoc, Lim in Ling, 2018, str. 139).</p>
<p>Vse spletne platforme, zlasti družbeni mediji, zagotavljajo prostor, kjer lahko ne-novinarji dosežejo množično občinstvo, oz. zagotavljajo priložnosti za državljansko novinarstvo. Ne-novinarji so se danes začeli vključevati v novinarske dejavnosti (Robinson &amp; DeShano, 2011, str. 965). Prek svojih računov na družbenih omrežjih objavljajo informacije, fotografije in videoposnetke o izrednih novicah, ki so jim bili priča (Jewitt, 2009, str. 231).</p>
<p>Družbeni mediji oblikujejo medijsko krajino na več načinov. Prvič, vsebine različnih ponudnikov novic so prikazane na enem mestu, uporabnikom ni več treba izbrati vira novic, temveč izberejo zgodbo samo (Messing in Westwood, 2014, str. 1044). Vir informacij je zabrisan, saj novice/informacije hitro potujejo od ene osebe/kanala do druge (Tandoc, Lim &amp; Ling, 2018, str. 139). Drugič, pri izbiri vsebine so vodilo, potrditve in družbena priporočila (Messing &amp; Westwood, 2014, str. 1044). Pri razširjanju ima pomembno vlogo tudi priljubljenost. Všečki, delitve ali komentarji sprožijo nadaljnje všečke, delitve ali komentarje (Thorson, 2008, str. 475).</p>
<p>Poleg tega za razliko od starih novičarskih medijev ni etičnega kodeksa o deljenju manipuliranih vsebin v družbenih medijih (Tandoc, Lim &amp; Ling, 2018, str. 144-145), prav tako pa obstajajo težave (ki včasih zahtevajo strokovno znanje) pri preverjanju informacij v različnih oblikah, kot so fotografije in videoposnetki.</p>
<p>Napačne informacije/dezinformacije so obstajale že pred tiskarskim strojem, vendar je internet omogočil, da se laži, teorije zarote in pretiravanja širijo hitreje in dlje kot kdaj koli prej (Klepper, 7. februar 2020).</p>
<h3 id="verodostojnost-spletnih-uporabnikov">Verodostojnost spletnih uporabnikov</h3>
<p>Verodostojnost uporabnikov spletnih skupnosti je še ena težava (Ortega, Troyano, Cruz, Vallejo in Enriquez, 2012, str. 2884). Vsa orodja in tudi nadarjenost za njihovo uporabo so danes naprodaj. Vsakdo lahko kupi na tisoče računov v družbenih medijih ali milijone elektronskih naslovov in najame pisce (plačane oglaševalce), ki bodo pomagali množično razširjati katero koli sporočilo ali ideologijo (Filloux, 2017).  </p>
<p>Obstajajo podjetja in posamezniki, ki po ugodnih cenah za Twitter, Facebook in YouTube odkrito prodajajo sledilce/naročnike in vključenost, ponovne tvite in deljenje objav (Barojan, 5. november 2018).</p>
<center>
<p><img src="img/part_01-module_04/figure_01.png"/></p>
<p>Vir: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, November 5, 2018</a></p>
</center>
<p>Družbeni mediji se vse pogosteje uporabljajo za širjenje lažnih trditev in polarizacijo ljudi glede spornih vprašanj. Kiborgi, troli in boti ogromno prispevajo k onesnaževanju informacij na spletu, saj ga polnijo z dezinformacijami (Klepper, 7. februar 2020).</p>
<center>
<p><img src="img/part_01-module_04/figure_03.png"/></p>
<p>Vir: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, November 5, 2018</a></p>
</center>
<h4 id="troli-in-farme-oz-tovarne-trolov">Troli in farme oz. tovarne trolov</h4>
<p>Beseda trol se nanaša na ljudi, ki namerno sprožajo spletne konflikte ali žalijo druge uporabnike, da bi odvrnili pozornost in zasejali delitve z objavljanjem vnetljivih ali ne tematskih objav v spletni skupnosti ali družbenem omrežju (Barojan, 5. november 2018; Wardle, 2018). Cilj je spodbuditi druge k čustvenemu odzivu in iztiriti razprave, včasih za lastno zabavo, včasih pa kot del usklajene kampanje (Klepper, 7. februar 2020). Organizirana skupina spletnih trolov se imenuje farma trolov ali tovarna trolov.</p>
<p>Včasih so troli za širjenje informacij plačani. Ustvarijo lahko pomemben (negativen/pozitiven) učinek na spletne skupnosti (Chen, Wu, Srinivasan in Zhang, 2013). Tako ustvarjena propaganda pogosto temelji na dejstvih, vendar vključuje pristranskost, ki spodbuja določen izdelek, stran ali stališče. Cilj takšnega mešanja novic in komentarjev je pogosto prepričevanje in ne informiranje (Tandoc, Lim &amp; Ling, 2018, str. 147).</p>
<p>Internet Water Army s Kitajske je na primer skupina, ki je plačana za objavljanje spletnih komentarjev z določeno vsebino na internetu. Te ljudi rekrutirajo podjetja, da na nekaterih spletnih platformah promovirajo pozitivne novice o njihovih izdelkih in negativne novice o konkurentih (Internet Water Army, 2020). Po drugi strani je 50 Cent Party/Army skupina komentatorjev, ki jih najemajo kitajske oblasti, da bi manipulirali z javnim mnenjem v korist kitajske komunistične partije. Ugotovitve harvardske raziskave ocenjujejo, da kitajska vlada vsako leto izdela približno 448 milijonov objav na družbenih omrežjih (King, Pan in Roberts, 2017; 50 Cent Party, 2020).</p>
<center>
<p><img src="img/part_01-module_04/figure_02.png"/></p>
<p>Vir: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, November 5, 2018</a></p>
</center>
<p>V zadnjem času je uporaba internetnih trolov za manipulacijo z mnenjem postala običajna praksa. Priljubljen način "trolanja" je objavljanje spornih objav na določeno temo iz lažnih profilov, katerih cilj je za vsako ceno zmagati v sporu, običajno jih spremljajo netočne in zavajajoče informacije (Mihaylov, Koychev, Georgiev in Nakov, 2015, str. 443).</p>
<div class="well">
<h5 id="primer-bill-gates-je-bil-tarca-trolov">Primer: Bill Gates je bil tarča trolov</h5>
<p>Napadi na družbenih omrežjih proti Billu Gatesu so se okrepili aprila 2020, ko je na Instagramu objavil videoposnetek, na katerem je v okno obesil napis "Hvala zdravstvenim delavcem". V naslednjih dneh je bila objava zasuta z več sto tisoč komentarji, ki so ga povezovali z različnimi teorijami zarote, povezanimi s cepivi, Svetovno zdravstveno organizacijo (WHO) in vstavljenimi mikročipi. Napadi so se okrepili naslednji teden, ko je kritiziral odločitev Trumpove administracije, da ustavi financiranje Svetovne zdravstvene organizacije. V 24 urah po komentarjih Billa Gatesa je bil njegov račun na Twitterju omenjen vsaj 270.000-krat –30-krat več od povprečja – predvsem s strani jeznih podpornikov predsednika Trumpa (Stronder, 21. maj 2020).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="img/part_01-module_04/figure_05.png"/></center></td>
<td><center><img src="img/part_01-module_04/figure_04.png"/><br/><br/><img src="img/part_01-module_04/figure_07.png"/></center></td>
</tr>
<tr>
<td><center><p>Vir: <a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank">Schlosser, April 15, 2020.</a></p></center></td>
<td><center><p>Vir: <a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank">Seetharaman, April 17, 2020.</a></p></center></td>
</tr>
</table></center>
</div>
<div class="well">
<h5 id="primer-troli-so-pred-volitvami-leta-2017-poskusali-vnesti-razdor-med-kanadcane">Primer: Troli so pred volitvami leta 2017 poskušali vnesti razdor med Kanadčane</h5>
<p>Ugotovitve raziskave, opravljene na 18.533 tvitih od januarja do februarja 2017, kažejo, da so troli pred volitvami leta 2017 skušali podžigati delitve med Kanadčani s tvitanjem lažnih novic in islamofobičnih izjav po streljanju v mošeji v Québecu leta 2017 (Al-Rawi &amp; Jiwani, 23. julij 2019).</p>
<center>
<p><img src="img/part_01-module_04/figure_06.png"/></p>
<p>Vir: <a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank">Al-Rawi &amp; Jiwani, July 23, 2019</a></p>
</center>
</div>
<p>Trol se razlikuje od bota, ker je trol pravi uporabnik, medtem ko so boti avtomatizirani. Trolanje kot dejavnost ni omejeno samo na trole. Troli včasih uporabljajo bote, da okrepijo nekatera svoja sporočila. Tako se lahko boti uporabljajo za namene trolanja (Barojan, 5. november 2018).</p>
<h4 id="srivni-racuni-angl-sock-puppet-accounts">Srivni računi (angl. Sock Puppet Accounts) </h4>
<p>Gre za vrsto lažnega računa. Medtem ko nekateri uporabniki uporabljajo anonimne račune samo zato, da se ne bi identificirali, pa lastnik  izmišljenega računa račun uporablja za napadanje kritikov ali hvaljenje samega sebe (Klepper, 7. februar 2020).</p>
<div class="well">
<h5 id="primer-racun-lutke-iz-nogavice-senatorja-zda">Primer: Račun lutke iz nogavice senatorja ZDA</h5>
<p>Senator iz ameriške zvezne države Utah Mitt Romney je priznal, da je upravljal skrivni račun na Twitterju pod imenom "Pierre Delecto", ki ga je uporabljal za obrambo pred kritikami (Klepper, 7. februar 2020).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="img/part_01-module_04/figure_09.png"/></center></td>
<td><center><img src="img/part_01-module_04/figure_08.png"/></center></td>
</tr>
</table></center>
<center><p>Vir: <a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank">Feinberg, October 20, 2019 </a></p></center>
</div>
<h4 id="boti-in-botneti">Boti in botneti</h4>
<p>Bot je avtomatiziran račun v družbenih medijih, ki ga upravlja algoritem in ne prava oseba. Z drugimi besedami, bot je zasnovan tako, da objavlja objave brez človeškega posredovanja. Trije ključni kazalniki botov so anonimnost, visoka stopnja aktivnosti in krepitev določenih uporabnikov, tem ali ključnikov (Barojan, 5. november 2018). Medtem ko avtentični uporabniki Twitterja pogosto objavljajo nekajkrat na dan o različnih temah, boti tvitajo več sto krat na dan in pogosto samo o določeni temi. Bolj verjetno je, da bodo vsebino ponovno objavili, kot da bi ustvarili nekaj izvirnega (Klepper, 7. februar 2020). Boti lahko uporabljajo ključnike in objavljajo vsebine, ki lahko na koncu vplivajo na algoritem različnih platform družbenih medijev (Stronder, 21. maj 2020).</p>
<p>Če račun piše posamezne objave in komentira, odgovarja ali kako drugače sodeluje z objavami drugih uporabnikov, ga ni mogoče uvrstiti med bote. Bote večinoma najdemo na Twitterju in drugih družbenih omrežjih, ki uporabnikom omogočajo ustvarjanje več računov (Barojan, 5. november 2018).</p>
<p>V dezinformacijskih kampanjah se lahko boti uporabljajo za opozarjanje na zavajajoče pripovedi, prevzemanje seznamov trendov platform ter ustvarjanje iluzije javne razprave in podpore (Wardle, 2018). Raziskovalci z Univerze Južne Kalifornije so v eni od raziskav analizirali tvite, povezane z ameriškimi volitvami, poslane septembra in oktobra 2016, in ugotovili, da je enega od petih poslal bot (Klepper, 7. februar 2020).</p>
<div class="well">
<h5 id="primer-med-izbruhom-pandemije-so-priblizno-45-tvitov-poslali-boti">Primer: Med izbruhom pandemije so približno 45 % tvitov poslali boti</h5>
<p>Po podatkih raziskovalcev z univerze Carnegie Mellon je skoraj polovica računov Twitter, ki so na platformi družbenih medijev širili sporočila o pandemiji koronavirusa, verjetno botov. Raziskovalci so na začetku izbruha pandemije pregledali več kot 200 milijonov tvitov o virusu in ugotovili, da so jih približno 45 % poslali računi, ki se obnašajo bolj kot boti. Raziskovalci so ugotovili več kot 100 vrst netočnih zgodb o virusu COVID-19, kot so tiste o morebitnih zdravilih. Boti so prevladovali tudi v pogovorih o ukinitvi ukrepov za ostajanje doma in "ponovnem odprtju Amerike" (Young, 27. maj 2020).</p>
<center><table class="table table-md">
<tr>
<td><center><img src="img/part_01-module_04/figure_12.png"/></center></td>
<td><center><img src="img/part_01-module_04/figure_10.png"/></center></td>
</tr>
<tr>
<td><center><p>Vir: <a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank">Young, May 27, 2020/</a></p></center></td>
<td><center><p>Vir: <a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank">SBenson, April, 24, 2020</a></p></center></td>
</tr>
</table></center>
</div>
<p>Botnet je omrežje bot računov, ki jih upravlja isti posameznik ali skupina. Tisti, ki upravljajo botnete, ki pred vzpostavitvijo zahtevajo prvotni človeški prispevek, se imenujejo ''bot herderji'' ali pastirji. Cilj botnetov je, da se o ključniku, uporabniku ali ključni besedi govori več (pozitivno ali negativno) ali da je bolj priljubljena, kot je v resnici. Boti ciljajo na algoritme družbenih medijev, da bi vplivali na rubriko trendi, kar bi nič hudega sluteče uporabnike izpostavilo pogovorom, ki jih okrepijo boti. Botneti redko ciljajo na človeške uporabnike, kadar pa to storijo, gre za pošiljanje neželene pošte ali splošno nadlegovanje, ne pa za aktivne poskuse spreminjanja njihovega mnenja ali političnih stališč (Barojan, 5. november 2018).</p>
<div class="well">
<h5 id="primer-pred-malezijskimi-volitvami-so-bile-zaznane-dejavnosti-botov">Primer: Pred malezijskimi volitvami so bile zaznane dejavnosti botov</h5>
<p>Pred volitvami v Maleziji je DFRLab odkril  22.000 botov, ki so vsi uporabljali popolnoma enak vzorec govora. Vsak bot je uporabljal dva ključnika, usmerjena proti opozicijski koaliciji, poleg tega pa je označil od 13 do 16 resničnih uporabnikov, da bi jih spodbudil k vključitvi v pogovor (Barojan, 5. november 2018).</p>
<center>
<img src="img/part_01-module_04/figure_11.png"/>
<p>Vir: <a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, November 5, 2018.</a></p>
</center>
</div>
<h4 id="kiborgi">Kiborgi</h4>
<p>Kiborg je neke vrste hibridni račun, ki združuje neutrudnost bota s človeško prefinjenostjo. Računi kiborg so tisti, pri katerih človek občasno prevzame račun bota, da se odziva na druge uporabnike in objavlja izvirno vsebino. Njihovo upravljanje je dražje in zamudnejše, vendar jih je veliko težje ujeti in odkriti (Klepper, 7. februar 2020).</p>
<h2 id="vaja">Vaja</h2>
<p>Trol je pravi uporabnik, medtem ko je bot avtomatiziran. Bota vodi algoritem in ne resnična oseba. Bot je zasnovan tako, da objavlja objave brez posredovanja človeka, medtem ko je kiborg neke vrste hibridni račun, ki združuje bota in pravo osebo.</p>
<h2 id="kviz">Kviz</h2>
<p><iframe allowfullscreen="allowfullscreen" frameborder="0" height="300" src="http://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&amp;id=116" title="SLO Essential MOOC: Part 1 - Module 4 - Quiz 1" width="936"></iframe><script charset="UTF-8" src="http://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js"></script></p>
<h2 id="reference">Reference</h2>
<p><a href="https://en.wikipedia.org/wiki/50_Cent_Party" target="_blank">50 Cent Party. (2020).</a> In Wikipedia.</p>
<p><a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank">Al-Rawi, A. &amp; Jiwani, J. (July 23, 2019).</a> Russian Twitter trolls stoke anti-immigrant lies ahead of Canadian election. The Conversation.<a href="https://theconversation.com/russian-twitter-trolls-stoke-anti-immigrant-lies-ahead-of-canadian-election-119144" target="_blank"></a></p>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank"></a></p>
<p><a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank">Benson, T. (April, 24, 2020).</a> Trolls and bots are flooding social media with disinformation encouraging states to end quarantine. Insider.<a href="https://www.businessinsider.com/trolls-bots-flooding-social-media-with-anti-quarantine-disinformation-2020-4?IR=T" target="_blank"></a></p>
<p><a href="https://www.semanticscholar.org/paper/Battling-the-Internet-water-army%3A-Detection-of-paid-Chen-Wu/26d0d7942e4c0cb24abef3abea6d763d4da668f5" target="_blank">Chen, C., Wu, K., Venkatesh, S. &amp; Zhang, X. (2013).</a> Battling the Internet Water Army: Detection of hidden paid posters. Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. Niagara, Canada: ACM.</p>
<p><a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank">Feinberg, A. (October 20, 2019).</a> This sure looks like Mitt Romney’s secret Twitter account (Update: It is): Meet “Pierre Delecto”. The Slate.<a href="https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html" target="_blank"> https://slate.com/news-and-politics/2019/10/mitt-romney-has-a-secret-twitter-account-and-it-sure-looks-like-its-this-one.html</a></p>
<p><a href="https://medium.com/the-walkley-magazine/you-cant-sell-news-for-what-it-costs-to-make-7a4def964ffa" target="_blank">Filloux, F. (2017).</a> You can’t sell news for what it costs to make. The Walkley Magazine on Medium.</p>
<p><a href="https://en.wikipedia.org/wiki/Internet_Water_Army" target="_blank">Internet Water Army. (2020).</a> In Wikipedia.</p>
<p><a href="https://www.academia.edu/40668891/The_trouble_with_twittering_integrating_social_media_into_mainstream_news" target="_blank">Jewitt, R. (2009).</a> The trouble with twittering: Integrating social media into mainstream news. International Journal of Media &amp; Cultural Politics, 5(3), 233–246. doi:10.1386/- macp.5.3.233_3</p>
<p><a href="https://gking.harvard.edu/files/gking/files/how_the_chinese_government_fabricates_social_media_posts_for_strategic_distraction_not_engaged_argument.pdf" target="_blank">King, G., Pan, J. &amp; Roberts, M. E. (2017).</a> How the Chinese government fabricates Social Media posts for strategic distraction, not engaged argument. American Political Science Review, 111(3), 484-501. DOI:<a href="http://dx.doi.org/10.1017/S0003055417000144" target="_blank"> 10.1017/S0003055417000144 </a></p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, D. (February 7, 2020).</a> Cyborgs, trolls and bots: A guide to online misinformation.<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank"></a></p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/0093650212466406" target="_blank">Messing, S., &amp; Westwood, S. J. (2014).</a> Selective exposure in the age of social media: Endorsements trump partisan source affiliation when selecting news online. Communication Research, 41(8), 1042-1063.</p>
<p><a href="https://www.aclweb.org/anthology/R15-1058.pdf" target="_blank">Mihaylov, T., Koychev, I., Georgiev, G.D. &amp; Nakov, P. (2015).</a> Exposing paid opinion manipulation trolls. In: Proceedings of Recent Advances in Natural Language Processing (pp. 443–450), Hissar, Bulgaria, Sep 7–9 2015.</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S138912861200179X" target="_blank">Ortega, F. J., Troyano, J., Cruz, F., Vallejo, C. &amp; Enriquez, F. (2012).</a> Propagation of trust and distrust for the detection of trolls in a social network. Computer Networks. 56. 2884-2895. 10.1016/j.comnet.2012.05.002.</p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1464884911415973" target="_blank">Robinson, S., &amp; DeShano, C. (2011).</a> ‘Anyone can know’: Citizen journalism and the interpretive community of the mainstream press. Journalism, 12(8), 963–982. doi:10.1177/1464884911415973.</p>
<p><a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank">Seetharaman, D. (April 17, 2020).</a> Bill Gates is targeted by Social-Media mobs. The Wall Street Journal.<a href="https://www.wsj.com/articles/bill-gates-is-targeted-by-social-media-mobs-11587133938" target="_blank"></a></p>
<p><a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank">Schlosser, K. (April 15, 2020).</a> Bill Gates calls Trump’s freeze on WHO funding ‘dangerous’ and tweet draws a viral response. GeekWire.<a href="https://www.geekwire.com/2020/bill-gates-calls-trumps-freeze-funding-dangerous-tweet-draws-viral-response/" target="_blank"></a></p>
<p><a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank">Stronder (May 21, 2020).</a> Fighting disinformation, trolls, and bots on social media during COVID-19.<a href="https://www.sotrender.com/blog/2020/05/fake-news-trolls-bots-social-media-covid/" target="_blank"></a></p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143" target="_blank">Tandoc, E.C., Lim, Z. W. &amp; Ling, R. (2018).</a> Defining “fake news”. Digital Journalism, 6(2), 137-153. DOI: 10.1080/21670811.2017.1360143</p>
<p><a href="https://www.tandfonline.com/doi/full/10.1080/13691180801999027" target="_blank">Thorson, E. (2008).</a> Changing patterns of news consumption and participation. Information, Communication and Society, 11(4), 473–489. doi:10.1080/13691180801999027.</p>
<p><a href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c" target="_blank">Wardle, C. &amp; Derakhshan, H. (2017).</a> Information disorder: Toward an interdisciplinary framework for research and policymaking. The Council of Europe.</p>
<p><a href="https://firstdraftnews.org/wp-content/uploads/2018/07/infoDisorder_glossary.pdf" target="_blank">Wardle, C. (2018).</a> The Essential Glossary.</p>
<p><a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank">Young, V. A. (May 27, 2020)</a>. Nearly half of the Twitter accounts discussing 'reopening America' may be bots. Carnegie Mellon University News.<a href="https://www.cmu.edu/news/stories/archives/2020/may/twitter-bot-campaign.html" target="_blank"></a></p>
<p><a href="https://www.ft.com/content/b4f27934-944a-11e8-b67b-b8205561c3fe" target="_blank">Yang, Y. (August 1, 2018). </a>China’s battle with the internet water army.</p>
<h2 id="priporoceni-viri">Priporočeni viri</h2>
<p><a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank">Barojan, D. (November 5, 2018).</a> How to Identify Bots, Trolls, and Botnets. Global Investigative Network.<a href="https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/" target="_blank"> https://gijn.org/2018/11/05/how-to-identify-bots-trolls-and-botnets/</a></p>
<p><a href="https://medium.com/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c" target="_blank">DFR Lab. (August 29, 2017).</a> #BotSpot: Twelve Ways to Spot a Bot: Some tricks to identify fake Twitter accounts.<a href="https://medium.com/dfrlab/botspot-twelve-ways-to-spot-a-bot-aedc7d9c110c" target="_blank"></a></p>
<p><a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank">Klepper, D. (February 7, 2020). </a>Cyborgs, trolls and bots: A guide to online misinformation.<a href="https://apnews.com/article/us-news-ap-top-news-elections-social-media-technology-4086949d878336f8ea6daa4dee725d94" target="_blank"></a></p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" target="_blank">Wild, J. &amp; Godart, C. (2020).</a> Spotting bots, cyborgs and inauthentic activity. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<p><a href="https://s3.eu-central-1.amazonaws.com/datajournalismcom/handbooks/Verification-Handbook-3.pdf" target="_blank">Zadrozny, B. (2020).</a> Investigating social media accounts. In C. Silverman (Ed.). Verification Handbook for Disinformation and Media Manipulation, 3rd Ed. European Journalism Centre.</p>
<h2 id="priporoceni-videoposnetki">Priporočeni videoposnetki</h2>
<p><a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" target="_blank">Associated Press. (2020).</a> Cyborgs, trolls and bots: AP explains online misinformation<a href="https://www.youtube.com/watch?v=ANUYiajYzF0&amp;t=116s" target="_blank"> </a></p>
</div><!--/span-->
</div><!--/row-->
</div><!--/.fluid-container-->
<!-- Le javascript
    ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="js/jquery-1.8.3.min.js"></script>
<script src="js/jquery-ui-1.9.1.custom.min.js"></script>
<script src="js/bootstrap.bundle.min.js"></script>
<script src="js/jquery.tocify.js"></script>
<script src="js/prettify.js"></script>
<script src="js/user_control.js"></script>
<script>
        $(function() {

            var toc = $("#toc").tocify({
              selectors: "h2,h3,h4,h5"
            }).data("toc-tocify");

            prettyPrint();
            $(".optionName").popover({ trigger: "hover" });

        });
    </script>
</body>
</html>